{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Simple Linear Regression ?**\n",
        "\n",
        "Simple Linear Regression is a basic statistical technique used to model the relationship between two variables: one independent variable (predictor or explanatory variable) and one dependent variable (response or outcome variable). It assumes that the relationship between the two variables can be represented as a straight line.\n",
        "\n",
        "The general formula for simple linear regression is:\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "+\n",
        "𝜖\n",
        "Y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X+ϵ"
      ],
      "metadata": {
        "id": "WQq9jDExyHKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What are the key assumptions of Simple Linear Regression**\n",
        "\n",
        "The key assumptons are -\n",
        "1. Linearity\n",
        "The relationship between the independent variable (\n",
        "𝑋\n",
        "X) and the dependent variable (\n",
        "𝑌\n",
        "Y) is linear. The data should follow a straight-line trend.\n",
        "2. Independence of Errors\n",
        "The residuals (differences between observed and predicted\n",
        "𝑌\n",
        "Y values) are independent of each other. There should be no correlation among residuals.\n",
        "3. Homoscedasticity\n",
        "The variance of the residuals is constant across all values of\n",
        "𝑋\n",
        "X. This means the spread of residuals is the same for all predicted values.\n",
        "4. Normality of Errors\n",
        "The residuals should follow a normal distribution. This assumption is particularly important for hypothesis testing and confidence interval construction.\n",
        "5. No Multicollinearity (Applies if multiple predictors are introduced later in extensions of the model)\n",
        "In Simple Linear Regression (with one predictor), this assumption is trivially satisfied because there is only one independent variable.\n",
        "6. No Measurement Error in Independent Variable\n",
        "The independent variable (\n",
        "𝑋\n",
        "X) is measured without error. Any error in measuring\n",
        "𝑋\n",
        "X can lead to biased estimates.\n",
        "\n",
        "   \n",
        ""
      ],
      "metadata": {
        "id": "NLeUs-ltznFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.What does the coefficient m represent in the equation Y=mX+c**\n",
        "\n",
        "In the equation\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c, the coefficient\n",
        "𝑚\n",
        "m represents the slope of the line. It indicates the rate of change of the dependent variable (\n",
        "𝑌\n",
        "Y) with respect to the independent variable (\n",
        "𝑋\n",
        "X).\n",
        "\n",
        "Meaning of\n",
        "𝑚\n",
        "m:\n",
        "Change in\n",
        "𝑌\n",
        "Y per unit change in\n",
        "𝑋\n",
        "X:\n",
        "𝑚\n",
        "m tells you how much\n",
        "𝑌\n",
        "Y increases or decreases for a one-unit increase in\n",
        "𝑋\n",
        "X.\n",
        "\n",
        "Positive\n",
        "𝑚\n",
        "m:\n",
        "If\n",
        "𝑚\n",
        ">\n",
        "0\n",
        "m>0,\n",
        "𝑌\n",
        "Y increases as\n",
        "𝑋\n",
        "X increases (positive correlation).\n",
        "\n",
        "Negative\n",
        "𝑚\n",
        "m:\n",
        "If\n",
        "𝑚\n",
        "<\n",
        "0\n",
        "m<0,\n",
        "𝑌\n",
        "Y decreases as\n",
        "𝑋\n",
        "X increases (negative correlation).\n",
        "\n",
        "Zero\n",
        "𝑚\n",
        "m:\n",
        "If\n",
        "𝑚\n",
        "=\n",
        "0\n",
        "m=0,\n",
        "𝑌\n",
        "Y does not change with\n",
        "𝑋\n",
        "X, indicating no relationship between\n",
        "𝑋\n",
        "X and\n",
        "𝑌\n",
        "Y."
      ],
      "metadata": {
        "id": "iX1tf9Tm0qEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.What does the intercept c represent in the equation Y=mX+c**\n",
        "\n",
        "\n",
        "In the equation\n",
        "𝑌\n",
        "=\n",
        "𝑚\n",
        "𝑋\n",
        "+\n",
        "𝑐\n",
        "Y=mX+c, the intercept\n",
        "𝑐\n",
        "c represents the point where the line crosses the\n",
        "𝑌\n",
        "Y-axis. In other words, it is the value of the dependent variable (\n",
        "𝑌\n",
        "Y) when the independent variable (\n",
        "𝑋\n",
        "X) is zero.\n",
        "\n",
        "Meaning of\n",
        "𝑐\n",
        "c:\n",
        "Baseline value of\n",
        "𝑌\n",
        "Y:\n",
        "It reflects the starting value of\n",
        "𝑌\n",
        "Y before any effect of\n",
        "𝑋\n",
        "X is considered.\n",
        "\n",
        "Point of intersection:\n",
        "When\n",
        "𝑋\n",
        "=\n",
        "0\n",
        "X=0,\n",
        "𝑌\n",
        "=\n",
        "𝑐\n",
        "Y=c. The intercept shows the position of the line on the\n",
        "𝑌\n",
        "Y-axis.\n",
        "\n"
      ],
      "metadata": {
        "id": "L9TEvlrs1fld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **5.How do we calculate the slope m in Simple Linear Regression**\n",
        "\n",
        "In Simple Linear Regression, the slope\n",
        "𝑚\n",
        "m is calculated using the formula:\n",
        "\n",
        "𝑚\n",
        "=\n",
        "Covariance between\n",
        "𝑋\n",
        " and\n",
        "𝑌\n",
        "Variance of\n",
        "𝑋\n",
        "m=\n",
        "Variance of X\n",
        "Covariance between X and Y\n",
        "​\n",
        "\n",
        "Or equivalently:\n",
        "\n",
        "𝑚\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "𝑖\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        ")\n",
        "(\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "ˉ\n",
        ")\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "𝑖\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "m=\n",
        "∑(X\n",
        "i\n",
        "​\n",
        " −\n",
        "X\n",
        "ˉ\n",
        " )\n",
        "2\n",
        "\n",
        "∑(X\n",
        "i\n",
        "​\n",
        " −\n",
        "X\n",
        "ˉ\n",
        " )(Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "ˉ\n",
        " )\n",
        "​\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "phVXeC-a2M6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.What is the purpose of the least squares method in Simple Linear Regression**\n",
        "\n",
        "Purpose of the Least Squares Method:\n",
        "Minimizing Error:\n",
        "\n",
        "The method minimizes the sum of the squared differences (errors) between the observed\n",
        "𝑌\n",
        "Y-values (\n",
        "𝑌\n",
        "𝑖\n",
        "Y\n",
        "i\n",
        "​\n",
        " ) and the predicted\n",
        "𝑌\n",
        "Y-values (\n",
        "𝑌\n",
        "^\n",
        "𝑖\n",
        "Y\n",
        "^\n",
        "  \n",
        "i\n",
        "​\n",
        " ) from the regression line.\n",
        "The error for each data point is calculated as\n",
        "𝑒\n",
        "𝑖\n",
        "=\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "^\n",
        "𝑖\n",
        "e\n",
        "i\n",
        "​\n",
        " =Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "^\n",
        "  \n",
        "i\n",
        "​\n",
        " .\n",
        "Objective:\n",
        "\n",
        "Minimize the sum of squared errors (SSE):\n",
        "𝑆\n",
        "𝑆\n",
        "𝐸\n",
        "=\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "(\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "^\n",
        "𝑖\n",
        ")\n",
        "2\n",
        "SSE=\n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " (Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "^\n",
        "  \n",
        "i\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "By squaring the errors, the method penalizes larger deviations more heavily, ensuring the best-fitting line reduces these discrepancies.\n",
        "Optimal Parameter Estimation:\n",
        "\n",
        "It determines the optimal values of the slope (\n",
        "𝑚\n",
        "m) and intercept (\n",
        "𝑐\n",
        "c) that produce the smallest possible SSE, making the line the \"best\" representation of the data.\n"
      ],
      "metadata": {
        "id": "EkimQInf2xcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.How is the coefficient of determination (R²) interpreted in Simple Linear Regression**\n",
        "\n",
        "The coefficient of determination (\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " ) is a statistical measure that indicates how well the independent variable (\n",
        "𝑋\n",
        "X) explains the variation in the dependent variable (\n",
        "𝑌\n",
        "Y) in a Simple Linear Regression model.\n",
        "\n",
        "Formula for\n",
        "𝑅\n",
        "2\n",
        "R\n",
        "2\n",
        " :\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "1\n",
        "−\n",
        "Sum of Squared Residuals (SSR)\n",
        "Total Sum of Squares (TSS)\n",
        "R\n",
        "2\n",
        " =1−\n",
        "Total Sum of Squares (TSS)\n",
        "Sum of Squared Residuals (SSR)\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑆\n",
        "𝑆\n",
        "𝑅\n",
        "SSR: Sum of Squared Residuals (\n",
        "∑\n",
        "(\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "^\n",
        "𝑖\n",
        ")\n",
        "2\n",
        "∑(Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "^\n",
        "  \n",
        "i\n",
        "​\n",
        " )\n",
        "2\n",
        " ) — the variation in\n",
        "𝑌\n",
        "Y not explained by the model.\n",
        "𝑇\n",
        "𝑆\n",
        "𝑆\n",
        "TSS: Total Sum of Squares (\n",
        "∑\n",
        "(\n",
        "𝑌\n",
        "𝑖\n",
        "−\n",
        "𝑌\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "∑(Y\n",
        "i\n",
        "​\n",
        " −\n",
        "Y\n",
        "ˉ\n",
        " )\n",
        "2\n",
        " ) — the total variation in\n",
        "𝑌\n",
        "Y.\n",
        "Alternatively:\n",
        "\n",
        "𝑅\n",
        "2\n",
        "=\n",
        "Explained Variation (ESS)\n",
        "Total Variation (TSS)\n",
        "R\n",
        "2\n",
        " =\n",
        "Total Variation (TSS)\n",
        "Explained Variation (ESS)\n",
        "​\n"
      ],
      "metadata": {
        "id": "D58PzO9K48p7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **8.What is Multiple Linear Regression**\n",
        "\n",
        " Multiple Linear Regression (MLR) is a statistical technique used to model the relationship between one dependent variable (\n",
        "𝑌\n",
        "Y) and two or more independent variables (\n",
        "𝑋\n",
        "1\n",
        ",\n",
        "𝑋\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑋\n",
        "𝑘\n",
        "X\n",
        "1\n",
        "​\n",
        " ,X\n",
        "2\n",
        "​\n",
        " ,…,X\n",
        "k\n",
        "​\n",
        " ).\n",
        "\n",
        "  It allows to understand and quantify how multiple factors collectively influence an outcome.\n",
        "\n",
        "General Equation:\n",
        "𝑌\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "𝛽\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝛽\n",
        "𝑘\n",
        "𝑋\n",
        "𝑘\n",
        "+\n",
        "𝜖\n",
        "Y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +β\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        "​\n",
        " +⋯+β\n",
        "k\n",
        "​\n",
        " X\n",
        "k\n",
        "​\n",
        " +ϵ"
      ],
      "metadata": {
        "id": "vgGv4lkf5YVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.What is the main difference between Simple and Multiple Linear Regression**\n",
        "\n",
        "Simple Linear Regression:\n",
        "If you are studying the effect of study hours (\n",
        "𝑋\n",
        "X) on exam scores (\n",
        "𝑌\n",
        "Y), the equation is:\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "+\n",
        "𝜖\n",
        "Y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X+ϵ\n",
        "\n",
        "Multiple Linear Regression:\n",
        "If you also consider additional factors like attendance (\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        " ) and sleep quality (\n",
        "𝑋\n",
        "3\n",
        "X\n",
        "3\n",
        "​\n",
        " ), the equation becomes:\n",
        "\n",
        "𝑌\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑋\n",
        "1\n",
        "+\n",
        "𝛽\n",
        "2\n",
        "𝑋\n",
        "2\n",
        "+\n",
        "𝛽\n",
        "3\n",
        "𝑋\n",
        "3\n",
        "+\n",
        "𝜖\n",
        "Y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +β\n",
        "2\n",
        "​\n",
        " X\n",
        "2\n",
        "​\n",
        " +β\n",
        "3\n",
        "​\n",
        " X\n",
        "3\n",
        "​\n",
        " +ϵ"
      ],
      "metadata": {
        "id": "ydUO1-Rp6ThA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.What are the key assumptions of Multiple Linear Regression**\n",
        "\n",
        "**Linearity**: The relationship between the dependent variable and the independent variables must be linear. This means the effect of each independent variable on the dependent variable is constant and additive.\n",
        "\n",
        "**Independence of Errors:** The residuals (errors) should be independent of each other. This assumption is crucial for valid hypothesis testing. Violation can lead to autocorrelation, especially in time series data.\n",
        "\n",
        "**Homoscedasticity:** The variance of the residuals (errors) should be constant across all levels of the independent variables. If the variance is not constant, the model is said to have heteroscedasticity, which can affect the reliability of statistical tests.\n",
        "\n",
        "**Normality of Errors:** The residuals should be approximately normally distributed. This assumption is particularly important for making inferences (such as hypothesis testing and confidence intervals). Non-normality can distort significance tests.\n",
        "\n",
        "**No Perfect Multicollinearity:** The independent variables should not be highly correlated with each other. If they are, it becomes difficult to isolate the effect of each independent variable on the dependent variable. This is known as multicollinearity and can lead to unreliable estimates.\n",
        "\n",
        "**No Measurement Error in Independent Variables:** All independent variables should be measured accurately. Errors in measuring the predictors can bias the model’s estimates and lead to incorrect conclusions.\n",
        "\n",
        "**Outliers:** Outliers in the data can disproportionately influence the regression model and skew results. It’s important to check for outliers that could distort the model's assumptions."
      ],
      "metadata": {
        "id": "TG74IJ2x7L8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model**\n",
        "\n",
        "Heteroscedasticity occurs when the variance of the errors (residuals) in a regression model is not constant across all levels of the independent variables. In other words, the spread or dispersion of the errors varies depending on the value of one or more predictors.\n",
        "\n",
        "Effects of Heteroscedasticity on Multiple Linear Regression:\n",
        "\n",
        "1.Inefficient Estimates:\n",
        "Heteroscedasticity violates the assumption of constant variance (homoscedasticity), which is critical for the ordinary least squares (OLS) method to provide the most efficient (minimum variance) estimates of the coefficients.\n",
        "\n",
        "2.Unreliable Hypothesis Testing:\n",
        "Standard errors of the regression coefficients become biased, leading to inaccurate t-tests and F-tests.\n",
        "As a result, you may incorrectly accept or reject null hypotheses.\n",
        "\n",
        "3.Incorrect Confidence Intervals:\n",
        "Biased standard errors result in incorrect confidence intervals for the regression coefficients, making predictions less reliable"
      ],
      "metadata": {
        "id": "vN6_bW0F8DJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12. How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "Ans.Multicollinearity occurs when two or more independent variables in a regression model are highly correlated, leading to redundancy and instability in the model. This can inflate the standard errors of the regression coefficients, making it difficult to determine their true effect.\n",
        "\n",
        "Steps to Address and Improve the Model:\n",
        "\n",
        "**1. Detect Multicollinearity**\n",
        "-Variance Inflation Factor (VIF):\n",
        "Calculate the VIF for each independent variable. A VIF > 5 or 10 indicates high multicollinearity.\n",
        "-Correlation Matrix:\n",
        "Compute pairwise correlations among independent variables to identify highly correlated pairs.\n",
        "\n",
        "**2. Remove Redundant Variable**\n",
        "Identify and drop one or more variables that are highly correlated with others to reduce redundancy. Select variables based on domain knowledge and their importance in predicting the target.\n",
        "\n",
        "**3. Combine or Transform Variables**\n",
        "Create a single composite variable (e.g., using principal component analysis or by summing related variables) to reduce multicollinearity."
      ],
      "metadata": {
        "id": "m1vjhZDg9zdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "Ans.Transforming categorical variables into a numerical format is essential for including them in regression models.\n",
        "\n",
        "Below are some common techniques for transforming categorical variables:\n",
        "**1. One-Hot Encoding**\n",
        "Converts each category of a variable into a binary column (0 or 1).\n",
        "Suitable for nominal (unordered) categories.\n",
        "\n",
        "**2. Label Encoding**\n",
        "Assigns a unique integer to each category.\n",
        "Suitable for ordinal (ordered) categories.\n",
        "\n",
        "**3. Binary Encoding**\n",
        "Encodes categories as binary digits and represents them in separate columns.\n",
        "Reduces the number of columns compared to one-hot encoding.\n",
        "\n",
        "**4. Mean Target Encoding**\n",
        "Replaces categories with the mean of the target variable for each category.\n",
        "Useful for categorical variables with high cardinality."
      ],
      "metadata": {
        "id": "x32DIhqv-Wb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14.What is the role of interaction terms in Multiple Linear Regression?**\n",
        "\n",
        "Ans.Interaction terms in a regression model capture the combined effect of two or more independent variables on the dependent variable that is not simply additive. They allow the model to account for situations where the effect of one independent variable depends on the value of another.\n",
        "\n",
        "Role of Interaction terms in Multiple Linear Regression:\n",
        "\n",
        "**1.Model Complex Relationships:**\n",
        "\n",
        "Some relationships between variables are not linear or additive. Interaction terms can model these complexities.\n",
        "For example, in a model predicting productivity, the effect of \"hours worked\" might depend on \"job experience.\"\n",
        "\n",
        "**2.Increase Model Flexibility:**\n",
        "\n",
        "Adding interaction terms allows the model to fit the data more closely by capturing nuanced relationships.\n",
        "\n",
        "**3.Improve Interpretability:**\n",
        "\n",
        "Interaction terms reveal dependencies between variables, offering deeper insights into how predictors influence the outcome together."
      ],
      "metadata": {
        "id": "ror-8eDI-1HR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "\n",
        "Ans.The interpretation of the intercept differs between Simple Linear Regression and Multiple Linear Regression due to the nature of the models and the presence of additional independent variables in the latter. Here’s how they differ:\n",
        "\n",
        "1. In Simple Linear Regression:\n",
        "Y=β0+β1X+ϵ\n",
        "Y: Dependent variable\n",
        "X: Independent variable\n",
        "𝛽0: Intercept\n",
        "\n",
        "2. Interpretation of the Intercept:\n",
        "The intercept 𝛽0 represents the predicted value of Y when 𝑋=0.\n",
        "It provides a baseline or starting point for the dependent variable in the absence of the independent variable.\n",
        "\n",
        "- In Multiple Linear Regression, the intercept is more abstract and depends on the context of all predictors being zero, which may not always be realistic or relevant. In such cases, the intercept serves as a mathematical constant rather than an interpretable feature.\n",
        "\n",
        "Y=β0+β1X1+β2X2+⋯+βnXn+ϵ\n",
        "X1,X2,…,Xn : Independent variables\n",
        "𝛽0: Intercept\n",
        "\n",
        "The intercept 𝛽0 represents the predicted value of Y when all independent variables are equal to 0."
      ],
      "metadata": {
        "id": "W10825UW_IoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16.What is the significance of the slope in regression analysis, and how does it affect predictions**\n",
        "\n",
        "**Significance of the Slope:**\n",
        "\n",
        "Magnitude and Direction: The slope indicates how much the dependent variable is expected to change for a one-unit change in an independent variable.\n",
        "\n",
        "A positive slope means that as the independent variable increases, the dependent variable also increases.\n",
        "A negative slope means that as the independent variable increases, the dependent variable decreases.\n",
        "Strength of Relationship: The larger the absolute value of the slope, the stronger the effect of that predictor on the dependent variable. A slope close to zero suggests a weak or no relationship between the variable and the outcome.\n",
        "\n",
        "**Statistical Significance:**\n",
        " A slope is considered statistically significant if the corresponding p-value is small (typically < 0.05), indicating that the relationship between the predictor and the dependent variable is unlikely to be due to chance. This is assessed through hypothesis testing (e.g., testing the null hypothesis that the slope is zero).\n",
        "\n",
        "**Impact on Predictions:**\n",
        "\n",
        "Influence on Predicted Values:\n",
        "The slope directly affects the predictions made by the model. For instance, in a simple linear regression with one predictor, the equation\n",
        "𝑦\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑥\n",
        "1\n",
        "y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " x\n",
        "1\n",
        "​\n",
        "  predicts the value of\n",
        "𝑦\n",
        "y based on the value of\n",
        "𝑥\n",
        "1\n",
        "x\n",
        "1\n",
        "​\n",
        " . If\n",
        "𝛽\n",
        "1\n",
        "β\n",
        "1\n",
        "​\n",
        "  (the slope) is large, a small change in\n",
        "𝑥\n",
        "1\n",
        "x\n",
        "1\n",
        "​\n",
        "  will result in a large change in\n",
        "𝑦\n",
        "y.\n",
        "\n",
        "**Interpreting Predictions:**\n",
        " If the slope is positive, you can predict that increasing the independent variable will lead to higher values of the dependent variable. If the slope is negative, increasing the independent variable will lead to lower values of the dependent variable."
      ],
      "metadata": {
        "id": "SJrMqI3r_R98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.How does the intercept in a regression model provide context for the relationship between variables**\n",
        "\n",
        "In a regression model, the intercept (often denoted as\n",
        "𝛽\n",
        "0\n",
        "β\n",
        "0\n",
        "​\n",
        " ) represents the value of the dependent variable when all the independent variables are set to zero. It gives us a baseline or starting point for the model, showing what the dependent variable would be in the absence of any predictors.\n",
        "\n",
        "Key Points about the Intercept:\n",
        "\n",
        "Baseline Value: The intercept is the predicted value of the dependent variable when all independent variables are zero. It provides a reference point for understanding how the predictors influence the outcome.\n",
        "\n",
        "Context for the Relationship:\n",
        "\n",
        " The intercept helps contextualize the relationship between variables. It shows the effect of the independent variables relative to a baseline condition (when they are zero).\n",
        "\n",
        "Example:\n",
        "\n",
        "Consider a regression model predicting house prices based on square footage:\n",
        "\n",
        "Price\n",
        "=\n",
        "50\n",
        ",\n",
        "000\n",
        "+\n",
        "150\n",
        "×\n",
        "Square Footage\n",
        "Price=50,000+150×Square Footage"
      ],
      "metadata": {
        "id": "q9Nv4-iWAVM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.What are the limitations of using R² as a sole measure of model performance**\n",
        "\n",
        "1. Does Not Indicate Causality:\n",
        "\n",
        "R² tells you how well the independent variables explain the variance in the dependent variable, but it doesn't establish a causal relationship. A high R² does not imply that the predictors cause the outcome to change, only that there is an association.\n",
        "\n",
        "2. Insensitive to Model Complexity:\n",
        "\n",
        "R² always increases when more predictors are added to a model, even if those predictors are irrelevant. This can lead to overfitting, where the model appears to fit the data well but performs poorly on new, unseen data.\n",
        "\n",
        "3. Not Reflective of Model Accuracy:\n",
        "\n",
        "A high R² does not necessarily mean that the model has accurate predictions. It simply indicates how well the model explains the variance in the data. A model could have a high R² but still make poor predictions, especially if it’s overfitting to noise in the training data.\n",
        "4. Does Not Capture Model Bias:\n",
        "\n",
        "R² does not provide information on whether the model has a bias (e.g., whether the model is systematically overestimating or underestimating the dependent variable). Two models with the same R² value can still have very different biases and prediction errors.\n",
        "\n",
        "5. Not Suitable for Non-Linear Relationships:\n",
        "\n",
        "R² assumes a linear relationship between the independent and dependent variables. For non-linear relationships, R² may not properly reflect the quality of the model. In such cases, other metrics or models (like polynomial regression or decision trees) may be more appropriate.\n",
        "\n",
        "6. Sensitive to Outliers:\n",
        "\n",
        "R² can be highly influenced by outliers or extreme values in the data. Even if the model fits most of the data well, a few outliers can artificially inflate or deflate R², making it misleading.\n",
        "\n",
        "7. Limited in Multivariate Contexts:\n",
        "\n",
        "In multiple regression models, R² might give a misleading impression of a good model fit, especially if there’s multicollinearity (high correlation between predictors). The relationship between the predictors and the outcome might seem strong, but the model could be unstable or unreliable."
      ],
      "metadata": {
        "id": "kueUNjUsDDl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.How would you interpret a large standard error for a regression coefficient**\n",
        "\n",
        "1. Lack of Precision in the Estimate:\n",
        "\n",
        "The standard error (SE) of a regression coefficient measures how much the estimated coefficient is expected to vary from sample to sample. A large standard error means that the coefficient estimate could vary widely, suggesting that the model is not providing a precise estimate for the effect of the corresponding independent variable on the dependent variable.\n",
        "\n",
        "2. Potential Multicollinearity:\n",
        "\n",
        "A large standard error often arises when there is multicollinearity in the data—meaning the independent variables are highly correlated with each other. When predictors are strongly correlated, it becomes difficult to isolate the effect of each predictor on the outcome, leading to larger standard errors for the coefficients. Multicollinearity inflates the standard errors and makes the model less stable.\n",
        "\n",
        "3. Insignificant or Weak Predictor:\n",
        "\n",
        "If a regression coefficient has a large standard error, it suggests that the predictor variable associated with that coefficient may not have a strong relationship with the dependent variable. This can make the coefficient less statistically significant.\n",
        "Statistically, a large standard error means that the t-statistic (which is the ratio of the coefficient to its standard error) will be small. A small t-statistic leads to a higher p-value, which can indicate that the predictor is not significantly contributing to the model.\n",
        "\n",
        "4. Insufficient Sample Size:\n",
        "\n",
        "A large standard error can also result from a small sample size. In small datasets, the estimates of the regression coefficients are more prone to variability, leading to larger standard errors. In such cases, the model might not have enough data to accurately estimate the coefficients, which reduces the precision of the estimates.\n",
        "\n",
        "5. Outliers or Data Issues:\n",
        "\n",
        "Outliers or data issues (such as measurement errors) can distort the regression model and inflate the standard error. If a few extreme values significantly affect the regression line, they can increase the variability of the coefficient estimate."
      ],
      "metadata": {
        "id": "N44OCnY5E8AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.How can heteroscedasticity be identified in residual plots, and why is it important to address it**\n",
        "\n",
        "Heteroscedasticity refers to the situation where the variance of the residuals (errors) is not constant across all levels of the independent variable(s). When heteroscedasticity is present, the spread of residuals increases or decreases as the value of the independent variable changes, which violates the assumption of constant variance (homoscedasticity) in regression models.\n",
        "\n",
        "Residuals vs. Fitted Values Plot:\n",
        "\n",
        "Plot the residuals (on the y-axis) against the fitted values or predicted values (on the x-axis).\n",
        "\n",
        "Scale-Location Plot (Spread-Location Plot):\n",
        "\n",
        "This plot shows the square root of the standardized residuals on the y-axis and the fitted values on the x-axis.\n",
        "If the residuals are evenly distributed across the fitted values, the plot will show a random scatter without any systematic pattern.\n",
        "\n",
        "**Why It’s Important to Address Heteroscedasticity:**\n",
        "\n",
        "Impact on Statistical Inferences:\n",
        "\n",
        "Inaccurate Standard Errors: Heteroscedasticity can lead to biased standard errors for the regression coefficients. This means the confidence intervals and significance tests (t-tests and F-tests) might not be reliable, leading to incorrect conclusions about the significance of predictors.\n",
        "\n",
        "Reduced Predictive Accuracy:\n",
        "\n",
        "If the model underestimates or overestimates the variance of the residuals in different ranges of the independent variable, predictions could become less reliable. This means the model might not be as accurate when applied to new data, especially if the data falls outside the range of the training set.\n",
        "Missed Model Refinement Opportunities:\n",
        "\n",
        "Heteroscedasticity can also indicate that the model is misspecified. For instance, it may suggest that some important predictors are missing from the model or that a non-linear relationship exists between the predictors and the dependent variable. Addressing heteroscedasticity can therefore lead to better model specification and performance."
      ],
      "metadata": {
        "id": "2NOHhLrBGWYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**\n",
        "\n",
        "Ans.When a Multiple Linear Regression model has a high R2 but a low Adjusted R2, it typically indicates that the model may be overfitting or that some of the predictors are not contributing significantly to explaining the variation in the dependent variable.\n",
        "\n",
        "1. R2(Coefficient of Determination):\n",
        "\n",
        "Measures the proportion of the variance in the dependent variable (Y) that is explained by the independent variables (X).R2 always increases (or stays the same) as more predictors are added, even if the predictors are not useful.\n",
        "\n",
        "2.Adjusted R2:\n",
        "\n",
        "Penalizes R2 for including predictors that do not improve the model significantly.\n",
        "Adjusted R2 accounts for both the number of predictors and the size of the dataset.\n",
        "Formula:\n",
        "\n",
        "Adjusted R2 = -1(1−R2)(n−1) / (n−k−1)\n",
        "where:\n",
        "n: Number of observations\n",
        "k: Number of predictors\n",
        "\n",
        "If adding a predictor does not improve the model enough to justify its inclusion, Adjusted R2 will decrease.\n"
      ],
      "metadata": {
        "id": "SiRCUB-FHo1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22. Why is it important to scale variables in Multiple Linear Regression?**\n",
        "\n",
        "Ans.Scaling variables in Multiple Linear Regression is important for several reasons, particularly when working with variables that have vastly different scales. Below are the key reasons why scaling is beneficial:\n",
        "\n",
        "1. Avoiding Dominance of Large-Scale Variables\n",
        "\n",
        "Variables with larger magnitudes can dominate those with smaller magnitudes in computations, especially in techniques that involve distance or magnitude (e.g., gradient descent optimization in some implementations of regression).\n",
        "Scaling ensures all variables are treated equally in the modeling process.\n",
        "\n",
        "2. Improving Numerical Stability\n",
        "\n",
        "In regression, scaling can prevent issues with numerical stability during matrix operations (e.g., calculating the inverse of the covariance matrix).\n",
        "Variables with widely different ranges can lead to rounding errors or inaccurate calculations.\n",
        "\n",
        "3. Simplifying Interpretation of Coefficients\n",
        "\n",
        "Scaling makes the interpretation of coefficients more intuitive when predictors have different units or magnitudes.\n",
        "After scaling:\n",
        "The regression coefficients represent the effect of a 1 standard deviation change in the predictor on the dependent variable.\n",
        "This allows for easier comparison of the relative importance of variables.\n",
        "\n",
        "4. Facilitating Regularization Techniques\n",
        "\n",
        "Techniques like Ridge Regression and Lasso Regression penalize large coefficients. If variables are not scaled, the penalty may disproportionately affect variables with smaller magnitudes, even if they are important predictors.\n",
        "Scaling ensures that penalties are applied fairly across all predictors."
      ],
      "metadata": {
        "id": "B7KMsB5VImQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23. What is polynomial regression?**\n",
        "\n",
        "Ans.Polynomial Regression is a type of regression analysis where the relationship between the independent variable (X) and the dependent variable (Y) is modeled as a polynomial of degree n. Unlike linear regression, which assumes a linear relationship between X and Y, polynomial regression can capture nonlinear relationships by introducing higher-degree terms of the independent variable.\n",
        "\n",
        "Mathematical Representation\n",
        "\n",
        "A polynomial regression model can be expressed as:\n",
        "\n",
        "𝑌=𝛽0+𝛽1𝑋+𝛽2𝑋2+𝛽3𝑋3+⋯+𝛽𝑛𝑋𝑛+𝜖\n",
        "\n",
        "Where:\n",
        "Y: Dependent variable\n",
        "X: Independent variable\n",
        "n: Degree of the polynomial\n",
        "𝛽0,𝛽1,…,𝛽𝑛β0,β1,…,βn: Coefficients to be determined\n",
        "ϵ: Error term"
      ],
      "metadata": {
        "id": "P9rDzvc5Io7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q24.How does polynomial regression differ from linear regression?**\n",
        "\n",
        "Ans.Polynomial regression and linear regression are both techniques used to model the relationship between independent and dependent variables. However, they differ in how they represent and handle this relationship. Below is a detailed comparison:\n",
        "\n",
        "1. Linear Regression:\n",
        " Assumes a linear relationship between the independent variable (X) and the dependent variable (Y).\n",
        "Y=β0+β1X+ϵ\n",
        "The model fits a straight line through the data points.\n",
        "Polynomial Regression: Models a nonlinear relationship between X and Y by including higher-degree terms of X (e.g.X2,X3).\n",
        "Y=β0+β1X+β2X2+⋯+βnXn+ϵ\n",
        "The model fits a curve through the data points.\n",
        "\n",
        "2. Flexibility in Capturing Patterns\n",
        "Linear Regression:\n",
        "Limited to capturing straight-line relationships.\n",
        "Poor at fitting data with curvature or complex patterns.\n",
        "\n",
        "Polynomial Regression:\n",
        "Can capture more complex, curved relationships.\n",
        "Allows for modeling of parabolic, cubic, or even higher-order trends in the data.\n",
        "\n",
        "3. Complexity\n",
        "Linear Regression:\n",
        "Simpler and easier to interpret because of the straight-line relationship.\n",
        "Fewer parameters to estimate, leading to less risk of overfitting.\n",
        "\n",
        "Polynomial Regression:\n",
        "More complex due to the inclusion of higher-order terms.\n",
        "Greater risk of overfitting as the degree of the polynomial increases."
      ],
      "metadata": {
        "id": "4N78KgJ6IpXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **25.When is polynomial regression used**\n",
        "\n",
        " Polynomial regression is used when the relationship between the independent variable(s) and the dependent variable is non-linear but still follows a predictable, smooth curve\n",
        " 1. Non-linear Relationships:\n",
        "\n",
        "Use case: Polynomial regression is ideal when you suspect that the relationship between the independent variable and the dependent variable is not linear, but instead forms a curve (e.g., quadratic, cubic).\n",
        "xample Equation:\n",
        "\n",
        "𝑦\n",
        "=\n",
        "𝛽\n",
        "0\n",
        "+\n",
        "𝛽\n",
        "1\n",
        "𝑥\n",
        "+\n",
        "𝛽\n",
        "2\n",
        "𝑥\n",
        "2\n",
        "+\n",
        "𝛽\n",
        "3\n",
        "𝑥\n",
        "3\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝜖\n",
        "y=β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " x+β\n",
        "2\n",
        "​\n",
        " x\n",
        "2\n",
        " +β\n",
        "3\n",
        "​\n",
        " x\n",
        "3\n",
        " +⋯+ϵ\n",
        "\n",
        " 2. When the Data Shows Curvature:\n",
        "\n",
        "Use case: Polynomial regression is applied when you observe that the residuals (the difference between the predicted and actual values) increase or decrease with the independent variable or display some form of curvature that a simple linear model can't capture.\n",
        "\n",
        "3. Improving Model Fit:\n",
        "\n",
        "Use case: Polynomial regression can improve the fit of a model if a linear regression fails to capture the underlying pattern in the data. By adding polynomial terms (like\n",
        "𝑥\n",
        "2\n",
        "x\n",
        "2\n",
        " ,\n",
        "𝑥\n",
        "3\n",
        "x\n",
        "3\n",
        " ), the model can better match the actual data points, reducing the residual sum of squares (RSS).\n",
        "\n",
        " 4. Modeling Complex Systems:\n",
        "\n",
        "Use case: When the relationship between variables is complex and not easily captured by simple linear regression, polynomial regression allows you to model intricate relationships by introducing higher-order terms."
      ],
      "metadata": {
        "id": "W6x5VUlfIp3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q26.What is the general equation for polynomial regression?**\n",
        "\n",
        "Ans.The general equation for a polynomial regression model is as follows:\n",
        "\n",
        "Y=β0+β1X+β2X2+β3X3+⋯+βnXn+ϵ\n",
        "Components of the Equation\n",
        "Y: The dependent variable (response or target).\n",
        "X: The independent variable (predictor or input).\n",
        "n: The degree of the polynomial (determines the highest power of X).\n",
        "β0,β1,…,βn : Coefficients of the polynomial terms\n",
        "ϵ: The error term."
      ],
      "metadata": {
        "id": "HRftCNO-JpdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q27.Can polynomial regression be applied to multiple variables?**\n",
        "\n",
        "Ans.Yes, polynomial regression can be applied to multiple variables. This is known as multivariable polynomial regression or multivariate polynomial regression. In this case, the relationship between the dependent variable Y and multiple independent variables\n",
        "X1,X2,…,Xp is modeled as a polynomial.\n",
        "\n",
        "Polynomial Features in Multiple Variables:\n",
        "In multivariable polynomial regression, we generate polynomial features that include interactions between the variables and higher-order terms. This helps capture complex relationships. For example, with two variables X1 and X2, the polynomial features might include:\n",
        "X12,X22 : Squared terms for each individual variable.\n",
        "X1X2: Interaction term between the two variables.\n",
        "\n",
        "So, for two predictors X1 and X2, a degree-2 polynomial model would look like this:\n",
        "\n",
        "Y=β0+β1X1+β2X2+β3X12+β4X22+β5X1X2+ϵ"
      ],
      "metadata": {
        "id": "xi1OnSVCMogF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**28.What are the limitations of polynomial regression**\n",
        "\n",
        "**Overfitting:**\n",
        "Problem: Polynomial regression can easily overfit the data, especially when a high-degree polynomial is used. Overfitting occurs when the model becomes too complex and fits the noise or random fluctuations in the data rather than the underlying pattern.\n",
        "\n",
        "**Increased Complexity:**\n",
        "Problem: As you increase the degree of the polynomial, the model becomes more complex and harder to interpret. Higher-degree polynomials introduce more terms (e.g.,\n",
        "𝑥\n",
        "2\n",
        ",\n",
        "𝑥\n",
        "3\n",
        ",\n",
        "𝑥\n",
        "4\n",
        ",\n",
        "…\n",
        "x\n",
        "2\n",
        " ,x\n",
        "3\n",
        " ,x\n",
        "4\n",
        " ,…), making the model harder to understand and analyze.\n",
        "\n",
        "**Extrapolation Problems:**\n",
        "Problem: Polynomial regression can produce unrealistic predictions outside the range of the training data. This is especially true for high-degree polynomials, which can cause predictions to grow very quickly or behave erratically as values move beyond the range of the data.\n",
        "\n",
        "**Sensitivity to Outliers:**\n",
        "Problem: Polynomial regression is highly sensitive to outliers, especially when higher-degree polynomials are used. Outliers can disproportionately influence the shape of the curve, leading to an inaccurate model."
      ],
      "metadata": {
        "id": "oBmzG_TgMv9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**29.What methods can be used to evaluate model fit when selecting the degree of a polynomial**\n",
        "\n",
        "**Cross-Validation:**\n",
        "Description: Cross-validation is a technique where you divide the dataset into multiple subsets (folds) and train the model on different subsets while testing it on the remaining data. This is repeated multiple times, and the model’s performance is averaged across all folds.\n",
        "\n",
        "**Training and Validation Error Comparison:**\n",
        "Description: You can split the dataset into a training set and a validation set. The model is trained on the training set and evaluated on the validation set.\n",
        "\n",
        "**Adjusted R²:**\n",
        "Description: The Adjusted R² is a version of the R² statistic that adjusts for the number of predictors in the model. While R² increases as the degree of the polynomial increases (because it always fits the data better), Adjusted R² penalizes models with unnecessary complexity (i.e., higher-degree polynomials).\n",
        "\n",
        "**Akaike Information Criterion (AIC) / Bayesian Information Criterion (BIC)**:\n",
        "Description: AIC and BIC are model selection criteria that take into account both the goodness of fit (e.g., likelihood) and the complexity of the model (number of parameters). Lower values of AIC and BIC indicate better models.\n"
      ],
      "metadata": {
        "id": "eUvBRYFZOU58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q30.Why is visualization important in polynomial regression?**\n",
        "\n",
        "Visualization is extremely important in polynomial regression for several reasons, especially because polynomial regression models can capture complex relationships that are difficult to understand or interpret purely through numerical output. Here’s why visualization matters:\n",
        "1. Understanding the Relationship\n",
        "Polynomial regression, especially with higher degrees, can produce nonlinear curves. Visualizing the data and the fitted polynomial curve allows you to understand the nature of the relationship between the independent variable(s) and the dependent variable.\n",
        "\n",
        "2. Detecting Overfitting\n",
        "Polynomial regression models, especially with high degrees, have a risk of overfitting. This happens when the model captures not just the underlying trend, but also the noise in the data, leading to a curve that oscillates dramatically between data points. Overfitting can be detected by visualizing:\n",
        "\n",
        "3. Model Comparison\n",
        "If you're experimenting with multiple polynomial degrees (e.g., quadratic, cubic, quartic), visualization can help you compare how each degree fits the data and choose the most appropriate degree of the polynomial.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ok80MkTgQcDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Q31.Steps to Implement Polynomial Regression in Python**\n",
        "1. Import Required Libraries\n",
        "First, you'll need to import the necessary libraries for data manipulation, polynomial feature expansion, linear regression modeling, and visualization.\n",
        "2. Prepare Your Data\n",
        "Let's assume you have a simple dataset with one feature (independent variable) and one target variable (dependent variable). For this example, we'll use some synthetic data.\n",
        "3. Feature Transformation (Polynomial Features)\n",
        "Polynomial regression requires transforming the features into polynomial form. You can use PolynomialFeatures from Scikit-learn to create polynomial features.\n",
        "4. Fit a Linear Regression Model\n",
        "Even though it's called polynomial regression, you still use linear regression to fit the transformed polynomial features.\n",
        "5. Make Predictions\n",
        "Once the model is trained, you can use it to make predictions."
      ],
      "metadata": {
        "id": "e2jF0ZFlSDle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Step 1: Prepare data\n",
        "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)  # Independent variable\n",
        "Y = np.array([1, 4, 9, 16, 25, 36, 49, 64, 81, 100])  # Dependent variable\n",
        "\n",
        "# Step 2: Transform features to polynomial features (degree 2)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Step 3: Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, Y)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "Y_pred = model.predict(X_poly)\n",
        "\n",
        "# Step 5: Visualize the results\n",
        "plt.scatter(X, Y, color='blue')  # Original data points\n",
        "plt.plot(X, Y_pred, color='red')  # Polynomial regression curve\n",
        "plt.title(\"Polynomial Regression\")\n",
        "plt.xlabel(\"Square Footage\")\n",
        "plt.ylabel(\"House Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "w4F1cxgvSVXc",
        "outputId": "52c73aa7-18f0-4e0d-998c-e27c1fd88242"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWIpJREFUeJzt3XmcjeX/x/HXmRmzMmOJWcxgyL6UJUL2iagQsmTtVynZxhp902oXCVlKobIzJKKEGEKS9ZssRQ3GWGfGkjFm7t8f99fhNGiGmblnzryfj8d5OPd13+c+nzMj5911X/d12QzDMBARERFxUi5WFyAiIiKSkRR2RERExKkp7IiIiIhTU9gRERERp6awIyIiIk5NYUdEREScmsKOiIiIODWFHREREXFqCjsiIiLi1BR2RLK5+vXrU79+favLSBezZ8/GZrNx7NixNL+2W7duFCtWLN1rclbFihWjW7duVpchkikUdkQy2Y0v9BsPT09PSpUqRa9evYiJibG6PKdXv359h5+/l5cXlSpVYuLEiSQnJ1tdnohkADerCxDJqd59911CQ0O5evUqmzdvZtq0aXzzzTfs378fb29vq8uzROfOnWnfvj0eHh4Z+j7BwcGMGjUKgLNnzzJv3jz69evHmTNnGDFiRIa+d1Zx8OBBXFz0/7uSMyjsiFikadOmVKtWDYAXX3yRAgUKMGHCBL766is6dOhgcXXWcHV1xdXVNcPfx8/Pj06dOtm3X3nlFcqUKcPkyZN59913M6WGG65evYq7u3umB4+MDpQiWYlivUgW0bBhQwCOHj0KwPXr13nvvfcoUaIEHh4eFCtWjNdff52EhIQ7nuPSpUv4+PjQt2/fFPuOHz+Oq6urvUfjxuW0LVu20L9/fwoWLIiPjw/PPPMMZ86cSfH6qVOnUr58eTw8PAgKCqJnz57ExsY6HFO/fn0qVKjA3r17qVevHt7e3jz44IMsWbIEgI0bN1KjRg28vLwoXbo033//vcPrbzdm56uvvuLJJ58kKCgIDw8PSpQowXvvvUdSUtK//1BTydPTk0ceeYSLFy9y+vRph31ffvklVatWxcvLi/z589O+fXuioqJSnOOjjz6iePHieHl5Ub16dSIjI1OMp/rhhx+w2WwsWLCAN954g8KFC+Pt7U18fDwA27dv54knnsDPzw9vb2/q1avHli1bHN7n4sWLhIeHU6xYMTw8PChUqBCPP/44v/zyi/2Yw4cP07p1awICAvD09CQ4OJj27dsTFxdnP+Z2Y3b++OMPnn32WfLnz4+3tzePPvooq1atcjjmxmdYtGgRI0aMIDg4GE9PTxo1asSRI0fS9HMXySwKOyJZxO+//w5AgQIFALO3580336RKlSp88MEH1KtXj1GjRtG+ffs7niN37tw888wzLFy4MEUYmD9/PoZh0LFjR4f23r17s2fPHt566y169OjB119/Ta9evRyOefvtt+nZsydBQUGMHz+e1q1bM2PGDBo3bkxiYqLDsRcuXOCpp56iRo0ajB07Fg8PD9q3b8/ChQtp3749zZo1Y/To0Vy+fJk2bdpw8eLFu/5cZs+eTe7cuenfvz8ffvghVatW5c0332TIkCF3/4Gm0bFjx7DZbOTNm9feNmLECLp06ULJkiWZMGEC4eHhrFu3jrp16zoEvWnTptGrVy+Cg4MZO3YsderUoWXLlhw/fvy27/Xee++xatUqBg4cyMiRI3F3d2f9+vXUrVuX+Ph43nrrLUaOHElsbCwNGzbkp59+sr/2lVdeYdq0abRu3ZqpU6cycOBAvLy8OHDgAADXrl2jSZMmbNu2jd69e/PRRx/RvXt3/vjjjxTh9FYxMTHUqlWLb7/9lldffZURI0Zw9epVmjdvzrJly1IcP3r0aJYtW8bAgQMZOnQo27ZtS/F3SyTLMEQkU82aNcsAjO+//944c+aMERUVZSxYsMAoUKCA4eXlZRw/ftzYvXu3ARgvvviiw2sHDhxoAMb69evtbfXq1TPq1atn3/72228NwFi9erXDaytVquRw3I06wsLCjOTkZHt7v379DFdXVyM2NtYwDMM4ffq04e7ubjRu3NhISkqyHzdlyhQDMD777DOHWgBj3rx59rbffvvNAAwXFxdj27ZtKeqcNWtWipqOHj1qb7ty5UqKn+HLL79seHt7G1evXrW3de3a1ShatGiKY/+pXr16RpkyZYwzZ84YZ86cMX777Tdj0KBBBmA8+eST9uOOHTtmuLq6GiNGjHB4/b59+ww3Nzd7e0JCglGgQAHjkUceMRITE+3HzZ492wAcfuYbNmwwAKN48eIOnys5OdkoWbKk0aRJE4ffxZUrV4zQ0FDj8ccft7f5+fkZPXv2vOPn27VrlwEYixcvvuvPoWjRokbXrl3t2+Hh4QZgREZG2tsuXrxohIaGGsWKFbP/7m98hrJlyxoJCQn2Yz/88EMDMPbt23fX9xWxgnp2RCwSFhZGwYIFCQkJoX379uTOnZtly5ZRuHBhvvnmGwD69+/v8JoBAwYApLi08M/zBgUFMXfuXHvb/v372bt3r8M4lRu6d++OzWazb9epU4ekpCT+/PNPAL7//nuuXbtGeHi4w7iSl156CV9f3xS15M6d26H3qXTp0uTNm5eyZctSo0YNe/uN53/88ccdPwuAl5eX/fnFixc5e/YsderU4cqVK/z22293fe2d/PbbbxQsWJCCBQtSpkwZxo0bR/PmzZk9e7b9mIiICJKTk2nbti1nz561PwICAihZsiQbNmwA4Oeff+bcuXO89NJLuLndHAbZsWNH8uXLd9v379q1q8Pn2r17N4cPH+a5557j3Llz9ve6fPkyjRo1YtOmTfY7xfLmzcv27ds5efLkbc/t5+cHwLfffsuVK1dS/TP55ptvqF69Oo899pi9LXfu3HTv3p1jx47x66+/Ohz//PPP4+7ubt+uU6cO8O+/TxEraICyiEU++ugjSpUqhZubG/7+/pQuXdoeJv78809cXFx48MEHHV4TEBBA3rx57UHkdlxcXOjYsSPTpk3jypUreHt7M3fuXDw9PXn22WdTHF+kSBGH7Rtf0BcuXLDXAmZouZW7uzvFixdPUUtwcLBDeALzCzgkJCRF263vcyf//e9/eeONN1i/fr19bMsNt45BSYtixYrxySefkJyczO+//86IESM4c+YMnp6e9mMOHz6MYRiULFnytufIlSsXcPPn88/flZub2x3n/QkNDXXYPnz4MGCGoDuJi4sjX758jB07lq5duxISEkLVqlVp1qwZXbp0oXjx4vZz9+/fnwkTJjB37lzq1KlD8+bN6dSpk/1nfjt//vmnQxi9oWzZsvb9FSpUsLf/298bkaxEYUfEItWrV7ffjXUn/wwNqdWlSxfGjRvH8uXL6dChA/PmzeOpp5667Zfdne48Mgzjnt77Tue7l/eJjY2lXr16+Pr68u6771KiRAk8PT355ZdfeO211+55XhwfHx/CwsLs27Vr16ZKlSq8/vrrTJo0CYDk5GRsNhurV6++be25c+e+p/cGx96qG+8FMG7cOB5++OHbvubG+7Vt25Y6deqwbNkyvvvuO8aNG8eYMWOIiIigadOmAIwfP55u3brx1Vdf8d1339GnTx9GjRrFtm3bCA4Ovue6b5Xef29EMpLCjkgWVLRoUZKTkzl8+LD9/6zBHEQaGxtL0aJF7/r6ChUqULlyZebOnUtwcDB//fUXkydPvudawJyX5UbvAZgDYY8ePeoQGtLbDz/8wLlz54iIiKBu3br29ht3rKWXSpUq0alTJ2bMmMHAgQMpUqQIJUqUwDAMQkNDKVWq1B1fe+Pnc+TIERo0aGBvv379OseOHaNSpUr/+v4lSpQAwNfXN1U/z8DAQF599VVeffVVTp8+TZUqVRgxYoQ97ABUrFiRihUr8sYbb/Djjz9Su3Ztpk+fzvDhw+/4OQ4ePJii/calwn/7OyeSlWnMjkgW1KxZMwAmTpzo0D5hwgQAnnzyyX89R+fOnfnuu++YOHEiBQoUcPgiTIuwsDDc3d2ZNGmSw/+1f/rpp8TFxaWqlnt1o/fg1ve9du0aU6dOTff3Gjx4MImJifafcatWrXB1deWdd95J0VthGAbnzp0DoFq1ahQoUIBPPvmE69ev24+ZO3duqi/pVK1alRIlSvD+++9z6dKlFPtvTAWQlJSU4tJdoUKFCAoKsk9JEB8f71AHmMHHxcXlrtMWNGvWjJ9++omtW7fa2y5fvszHH39MsWLFKFeuXKo+i0hWpJ4dkSzooYceomvXrnz88cf2Szk//fQTc+bMoWXLlg49CHfy3HPPMXjwYJYtW0aPHj3sY0zSqmDBggwdOpR33nmHJ554gubNm3Pw4EGmTp3KI488cttBz+mlVq1a5MuXj65du9KnTx9sNhtffPFFhlwqKVeuHM2aNWPmzJkMGzaMEiVKMHz4cIYOHcqxY8do2bIlefLk4ejRoyxbtozu3bszcOBA3N3defvtt+nduzcNGzakbdu2HDt2jNmzZ1OiRIlUXYp0cXFh5syZNG3alPLly/P8889TuHBhTpw4wYYNG/D19eXrr7/m4sWLBAcH06ZNGx566CFy587N999/z44dOxg/fjwA69evp1evXjz77LOUKlWK69ev88UXX+Dq6krr1q3vWMOQIUOYP38+TZs2pU+fPuTPn585c+Zw9OhRli5dqtmWJVtT2BHJombOnEnx4sWZPXs2y5YtIyAggKFDh/LWW2+l6vX+/v40btyYb775hs6dO99XLW+//TYFCxZkypQp9OvXj/z589O9e3dGjhx5zyEqNQoUKMDKlSsZMGAAb7zxBvny5aNTp040atSIJk2apPv7DRo0iFWrVjF58mTefvtthgwZQqlSpfjggw945513AAgJCaFx48Y0b97c/rpevXphGAbjx49n4MCBPPTQQ6xYsYI+ffo4DHq+m/r167N161bee+89pkyZwqVLlwgICKBGjRq8/PLLAHh7e/Pqq6/y3Xff2e8We/DBB5k6dSo9evQAzKDcpEkTvv76a06cOIG3tzcPPfQQq1ev5tFHH73j+/v7+/Pjjz/y2muvMXnyZK5evUqlSpX4+uuvM7T3TiQz2AyNJhNxWs888wz79u3TzLYWSE5OpmDBgrRq1YpPPvnE6nJEcjT1S4o4qejoaFatWnXfvTry765evZri0trnn3/O+fPnHZaLEBFrqGdHxMkcPXqULVu2MHPmTHbs2MHvv/9OQECA1WU5tR9++IF+/frx7LPPUqBAAX755Rc+/fRTypYty86dOx0m3xORzKcxOyJOZuPGjTz//PMUKVKEOXPmKOhkgmLFihESEsKkSZM4f/48+fPnp0uXLowePVpBRyQLUM+OiIiIODWN2RERERGnprAjIiIiTk1jdjBvET158iR58uS557WIREREJHMZhsHFixcJCgq668SXCjvAyZMnU6zILCIiItlDVFTUXRe5VdgB8uTJA5g/LF9fX4urERERkdSIj48nJCTE/j1+Jwo7YL905evrq7AjIiKSzfzbEBQNUBYRERGnprAjIiIiTk1hR0RERJyawo6IiIg4NYUdERERcWoKOyIiIuLUFHZERETEqSnsiIiIiFNT2BERERGnphmURUREJEMkJUFkJERHQ2Ag1KkDrq6ZX4elPTubNm3i6aefJigoCJvNxvLlyx32G4bBm2++SWBgIF5eXoSFhXH48GGHY86fP0/Hjh3x9fUlb968vPDCC1y6dCkTP4WIiIj8U0QEFCsGDRrAc8+ZfxYrZrZnNkvDzuXLl3nooYf46KOPbrt/7NixTJo0ienTp7N9+3Z8fHxo0qQJV69etR/TsWNH/vvf/7J27VpWrlzJpk2b6N69e2Z9BBEREfmHiAho0waOH3dsP3HCbM/swGMzDMPI3Le8PZvNxrJly2jZsiVg9uoEBQUxYMAABg4cCEBcXBz+/v7Mnj2b9u3bc+DAAcqVK8eOHTuoVq0aAGvWrKFZs2YcP36coKCgVL13fHw8fn5+xMXFaSFQERGR+5CUZPbg3Ag6pTgIwCFKA2CzQXAwHD16/5e0Uvv9nWUHKB89epRTp04RFhZmb/Pz86NGjRps3boVgK1bt5I3b1570AEICwvDxcWF7du33/HcCQkJxMfHOzxERETk/kVG3gw6ubnIclqyg0eoxw8AGAZERZnHZZYsG3ZOnToFgL+/v0O7v7+/fd+pU6coVKiQw343Nzfy589vP+Z2Ro0ahZ+fn/0REhKSztWLiIjkTNHRN54ZfMoLlOU3LpKHXyl3h+MyXpYNOxlp6NChxMXF2R9RUVFWlyQiIuIUAgPNP/vyIW1ZTCJuPMtizlDotsdlhiwbdgICAgCIiYlxaI+JibHvCwgI4PTp0w77r1+/zvnz5+3H3I6Hhwe+vr4ODxEREbl/derAMwU3M45BAPRnAlupZd9vs0FIiHlcZsmyYSc0NJSAgADWrVtnb4uPj2f79u3UrFkTgJo1axIbG8vOnTvtx6xfv57k5GRq1KiR6TWLiIjkdK5nTjH3eltycZ15dGAKvez7bDbzz4kTM3e+HUsnFbx06RJHjhyxbx89epTdu3eTP39+ihQpQnh4OMOHD6dkyZKEhoYybNgwgoKC7HdslS1blieeeIKXXnqJ6dOnk5iYSK9evWjfvn2q78QSERGRdJKYCO3a4XUhmriQ8ryd9AmctNl3BwebQadVq8wty9Kw8/PPP9OgQQP7dv/+/QHo2rUrs2fPZvDgwVy+fJnu3bsTGxvLY489xpo1a/D09LS/Zu7cufTq1YtGjRrh4uJC69atmTRpUqZ/FhERkRxv6FDYtAny5MHv+wgOlPDJEjMoZ5l5dqykeXZERETu05Il8Oyz5vOlSzOl+ybbz7MjIiIi2cRvv8Hzz5vPBw3K/OtU/0JhR0RERO7dpUtmuLl0CerXh5Ejra4oBYUdERERuTeGAS++CAcOmINyFiwAN0uHA9+Wwo6IiIjcm0mTYOFCM+AsXgz/WPUgq1DYERERkbTbsgX+t1A3778PtWtbW89dKOyIiIhI2sTEmHdeXb8O7dpBnz5WV3RXCjsiIiKSetevQ/v25uQ55crBzJk3p0bOohR2REREJPVefx1++AFy5zbn08md2+qK/pXCjoiIiKRORASMG2c+nzULypSxtp5UUtgRERGRf3fwIHTrZj4fMADatLG0nLRQ2BEREZG7u3wZWreGixehbl0YPdrqitJEYUdERETuzDDgpZfgv/+FgICb8+pkIwo7IiIicmdTpsD8+eZy5YsWmYEnm1HYERERkdv78Ufo3998Pm4c1KljbT33SGFHREREUrp14sC2bSE83OqK7pnCjoiIiDi6MXHgyZPm7eXZYOLAu1HYEREREUf/+c/NiQMjIiBPHqsrui8KOyIiInLTsmUwdqz5/LPPoGxZa+tJBwo7IiIiYjp8+ObEgf36mWN2nIDCjoiIiJgTB7ZqBfHx8NhjMGaM1RWlG4UdERGRnM4w4OWXYf9+cx6dRYsgVy6rq0o3CjsiIiI53dSpMHeuOXHgwoUQGGh1RelKYUdERCQn27bNHJ8D5qWrunWtrScDKOyIiIjkVKdPm6uXJyaaf96YLdnJKOyIiIjkRNevQ4cOcOIElC5t3maejScOvBuFHRERkZxo2DBYvx58fJxi4sC7UdgRERHJab76CkaPNp9/+imUK2dtPRlMYUdERCQnOXwYunQxn/ftC+3aWVtPJlDYERERySmuXIHWrc2JA2vXhnHjrK4oUyjsiIiI5ASGAa+8Avv2gb+/000ceDcKOyIiIjnB9OnwxRc3Jw4MCrK6okyjsCMiIuLstm83x+cAjBoF9epZW08mU9gRERFxZmfO3Jw4sFUrGDjQ6ooyncKOiIiIs0pKgueeg+PHoVQpmDXLaScOvBuFHREREWf15pvw/ffg7W1OHOjra3VFllDYERERcUYrVsDIkebzmTOhfHlr67GQwo6IiIizOXLk5sSBvXuba2DlYAo7IiIizuTGxIFxcVCzJrz/vtUVWU5hR0RExFkYBvToAXv3QqFCsHgxuLtbXZXlFHZEREScxYwZ8Pnn4OICCxZA4cJWV5QlKOyIiIg4g59+ujlx4MiR0KCBtfVkIQo7IiIi2d3Zs+bEgdeuQcuWMHiw1RVlKQo7IiIi2dmNiQOjoqBkSZg9O0dOHHg3CjsiIiLZ2dtvw9q14OUFS5eCn5/VFWU5CjsiIiLZ1cqVMHy4+fyTT6BiRWvryaIUdkRERLKjP/6Azp3N5z17QseO1taThSnsiIiIZDd//21OHBgbC48+ChMmWF1RlqawIyIikp0YBrz6KuzeDQULauLAVFDYERERyU4++cS848rFBebPh+BgqyvK8hR2REREsosdO8yFPcEcmNyokbX1ZBMKOyIiItnBrRMHNm8Or71mdUXZhsKOiIhIVpeUZN5t9ddfUKIEzJljXsaSVHGzugARERFxlJQEkZEQHQ2BgVB33bu4fPedOXFgRATkzWt1idmKwo6IiEgWEhFhrud5/Li53ZRvqM+75saMGVCpknXFZVMKOyIiIllERIQ5LMcwzO1iHOVLOgEwjR74+3SmlYX1ZVe64CciIpIFJCWZPTo3go4nf7OU1uTnAtupTj8+IDzcPE7SRmFHREQkC4iMvHnpCgym0Isq7OIMD9CGJSTgQVSUeZykTZYOO0lJSQwbNozQ0FC8vLwoUaIE7733HsaN2AsYhsGbb75JYGAgXl5ehIWFcfjwYQurFhERSbvo6JvPB/I+L/AZSbjQgfkcJ+S2x0nqZOmwM2bMGKZNm8aUKVM4cOAAY8aMYezYsUyePNl+zNixY5k0aRLTp09n+/bt+Pj40KRJE65evWph5SIiImkTGGj+2YbFjGMwYIaedYTd9jhJPZtxazdJFvPUU0/h7+/Pp59+am9r3bo1Xl5efPnllxiGQVBQEAMGDGDgwIEAxMXF4e/vz+zZs2nfvn2q3ic+Ph4/Pz/i4uLw9fXNkM8iIiJyN0lJ0CZwC/PPNMKTBCbRm758CNgAsNnMlSGOHgVXV2trzSpS+/2dpXt2atWqxbp16zh06BAAe/bsYfPmzTRt2hSAo0ePcurUKcLCbqZePz8/atSowdatW+943oSEBOLj4x0eIiIiVnL94zALrrbAkwS+ojn9+IBbgw7AxIkKOvciS996PmTIEOLj4ylTpgyurq4kJSUxYsQIOnbsCMCpU6cA8Pf3d3idv7+/fd/tjBo1infeeSfjChcREUmLs2ehWTM8Lp7jQolqDPp7Hsknb6aa4GAz6LTSfef3JEuHnUWLFjF37lzmzZtH+fLl2b17N+Hh4QQFBdG1a9d7Pu/QoUPp37+/fTs+Pp6QkJC7vEJERCSD/P03tGgBR45A0aLk2/w1Bwr6OMygXKeOenTuR5YOO4MGDWLIkCH2sTcVK1bkzz//ZNSoUXTt2pWAgAAAYmJiCLxlxFZMTAwPP/zwHc/r4eGBh4dHhtYuIiLyr5KToWtX+PFH8PODb76BgABcgfr1rS7OeWTpMTtXrlzB5R8Lnbm6upKcnAxAaGgoAQEBrFu3zr4/Pj6e7du3U7NmzUytVUREJM2GDoXFiyFXLli2DMqVs7oip5Sle3aefvppRowYQZEiRShfvjy7du1iwoQJ/N///R8ANpuN8PBwhg8fTsmSJQkNDWXYsGEEBQXRsmVLa4sXERG5m+nTYexY8/mnn0KDBtbW48SydNiZPHkyw4YN49VXX+X06dMEBQXx8ssv8+abb9qPGTx4MJcvX6Z79+7Exsby2GOPsWbNGjw9PS2sXERE5C6++QZ69jSfv/MOdO5sbT1OLkvPs5NZNM+OiIhkml27zBHHly9Dt27w2Wc37y2XNHGKeXZEREScSlQUPPmkGXQaNYIZMxR0MoHCjoiISGaIi4Nmzcz7ycuXhyVLwN3d6qpyBIUdERGRjJaYCG3awP79EBAAq1ZB3rxWV5VjKOyIiIhkJMOAV16B778HHx8z6BQtanVVOYrCjoiISEYaOdIchOziAgsWQJUqVleU4yjsiIiIZJS5c+GNN8znkyfDU09ZW08OpbAjIiKSETZuhOefN58PHAivvmptPTmYwo6IiEh6O3AAWrY0Bya3bg1jxlhdUY6msCMiIpKeYmLMW8xjY6FmTfjiC3O8jlhGP30REZH0cuUKPP00HDsGJUrAV1+Bl5fVVeV4CjsiIiLpISkJOnaEHTsgf35z/auCBa2uSlDYERERSR8DB8Ly5easyF99BaVKWV2R/I/CjoiIyP2aNAkmTjSff/45PPaYpeWII4UdERGR+/HVVxAebj4fPRratbO0HElJYUdERORe7dgBHTqYS0J07w6DB1tdkdyGwo6IiMi9OHrUnBH577/hiSfgo4/AZrO6KrkNhR0REZG0unDBnEvn9Gl46CFYtAjc3KyuSu5AYUdERCQtEhKgVSv47TcoXNhcxTxPHqurkrtQ2BEREUktw4AXX4QffjADzjffmIFHsjSFHRERkdR66y348ktwdYUlS6BSJasrklRQ2BEREUmNWbPgvffM59OnQ+PG1tYjqaawIyIi8m++/968tRzg9dfNS1mSbSjsiIiI3M3+/dC6NVy/bs6pc6N3R7INhR0REZE7OXnSvMU8Ph7q1DEvZbnoqzO70W9MRETkdi5dMicNjIqC0qXNRT49PKyuSu6Bwo6IiMg/Xb8O7dvDrl1QsKB5i3n+/FZXJfdIYUdERORWhgF9+piTBXp6wtdfQ/HiVlcl90FhR0RE5Fbjx8O0aeY6V3PnQo0aVlck90lhR0RE5IbFi2HQIPP5+PHmshCS7SnsiIiIAPz4I3TubD7v3RvCwy0tR9KPwo6IiMiRI9CihbnI59NPwwcfmJexxCko7IiISM529iw0bWr+WbUqzJ9vrn0lTkNhR0REcq6rV6FlS7Nnp2hRWLkSfHysrkrSmcKOiIjkTMnJ0LUrbNkCfn7mXDoBAVZXJRlAYUdERHKm11+HRYsgVy6IiIBy5ayuSDKIwo6IiOQ8M2bAmDHm85kzoWFDa+uRDKWwIyIiOcvq1dCzp/n8nXegSxdr65EMp7AjIiI5x+7d0LYtJCWZ43WGDbO6IskECjsiIpIzREXBk0+aq5k3bAgff6y5dHIIhR0REXF+8fFm0Dl5EsqXh6VLwd3d6qokkyjsiIiIc0tMhDZtYN8+89byVasgb16rq5JMpLAjIiLOyzCgRw9Yuxa8vc1JA4sWtboqyWRuVhcgIiKSXpKSIDISoqMhMBDqbh6Fy6efgosLLFxoLgchOY7CjoiIOIWICOjbF44fN7c7MI/6/MfcmDwZnnrKuuLEUgo7IiKS7UVEmMNyDMPcrsMmZvE8AOMZQGjAq7SysD6xlsbsiIhItpaUZPbo3Ag6pfmN5bTEg2ssoTWDGUt4uHmc5EwKOyIikq1FRt68dBXECb6hGfm5wFYepTNfkIwLUVHmcZIzKeyIiEi2Fh1t/hlANBtoQHGOcoQSNGcFV/FKcZzkPAo7IiKSrQUGgj+nWE9DSnGYYxSlEes4S8EUx0nOpLAjIiLZWp3Sp9no1oiy/MZfhNCADfzFzbl0bDYICYE6dSwsUiylsCMiItnX2bO4Nm5E6eu/cpzCNGQDxwi1776x9NXEieDqak2JYj2FHRERyZ7OnYOwMNi/HwID+e/kDSQEl3A4JDgYliyBVrrvPEfTPDsiIpL9XLgAjz8Oe/aAvz9s2ECT0iU51sNxBuU6ddSjIwo7IiKS3cTGQuPGsGsXFCwI69dD6dKAGWzq17e0OsmC7ukyVmRkJJ06daJmzZqcOHECgC+++ILNmzena3EiIiIO4uPhiSfg55/hgQfMoFOunNVVSRaX5rCzdOlSmjRpgpeXF7t27SIhIQGAuLg4Ro4cme4FioiIAHDxIjRtCtu3Q/788P33UKGC1VVJNpDmsDN8+HCmT5/OJ598Qq5cuezttWvX5pdffknX4gBOnDhBp06dKFCgAF5eXlSsWJGff/7Zvt8wDN58800CAwPx8vIiLCyMw4cPp3sdIiJioUuXoFkz+PFHyJvXDDoPPWR1VZJNpDnsHDx4kLp166Zo9/PzIzY2Nj1qsrtw4QK1a9cmV65crF69ml9//ZXx48eTL18++zFjx45l0qRJTJ8+ne3bt+Pj40OTJk24evVqutYiIiIWuXzZXLF882bw84O1a6FyZaurkmwkzQOUAwICOHLkCMWKFXNo37x5M8WLF0+vugAYM2YMISEhzJo1y94WGnpz/gTDMJg4cSJvvPEGLVq0AODzzz/H39+f5cuX0759+3StR0REMtmVK9C8OWzcCL6+8N13UK2a1VVJNpPmnp2XXnqJvn37sn37dmw2GydPnmTu3LkMHDiQHj16pGtxK1asoFq1ajz77LMUKlSIypUr88knn9j3Hz16lFOnThEWFmZv8/Pzo0aNGmzdujVdaxERkUx29Sq0bGkOQs6dG9asgerVra5KsqE09+wMGTKE5ORkGjVqxJUrV6hbty4eHh4MHDiQ3r17p2txf/zxB9OmTaN///68/vrr7Nixgz59+uDu7k7Xrl05deoUAP7+/g6v8/f3t++7nYSEBPvAaoD4+Ph0rVtERO5TQgI884x5ycrHB1avhpo1ra5Ksqk0hx2bzcZ//vMfBg0axJEjR7h06RLlypUjd+7c6V5ccnIy1apVs9/lVblyZfbv38/06dPp2rXrPZ931KhRvPPOO+lVpoiIpKeEBGjd2uzJ8faGb76Bxx6zuirJxtJ8GSsuLo7z58/j7u5OuXLlqF69Orlz5+b8+fPp3kMSGBhIuX/Mn1C2bFn++usvwBw/BBATE+NwTExMjH3f7QwdOpS4uDj7IyoqKl3rFhGRe3TtGrRrB6tWgZcXrFwJt7kpRiQt0hx22rdvz4IFC1K0L1q0KN0HBNeuXZuDBw86tB06dIiiRc3VbENDQwkICGDdunX2/fHx8Wzfvp2ad+nu9PDwwNfX1+EhIiIWS0yEDh3gq6/A0xNWrIAGDayuSpxAmsPO9u3baXCbv3z169dn+/bt6VLUDf369WPbtm2MHDmSI0eOMG/ePD7++GN69uwJmJfUwsPDGT58OCtWrGDfvn106dKFoKAgWrZsma61iIhIBrp+HTp2hIgIcHeH5cvNRT5F0kGax+wkJCRw/fr1FO2JiYn8/fff6VLUDY888gjLli1j6NChvPvuu4SGhjJx4kQ6duxoP2bw4MFcvnyZ7t27Exsby2OPPcaaNWvw9PRM11pERCSDXL8OnTvD4sWQKxcsWwZNmlhdlTgRm2EYRlpe0KBBAypUqMDkyZMd2nv27MnevXuJjIxM1wIzQ3x8PH5+fsTFxemSlohIZkpKgm7d4MsvzaCzdCk8/bTVVUk2kdrv7zT37AwfPpywsDD27NlDo0aNAFi3bh07duzgu+++u/eKRUQkZ0lOhhdeMIOOmxssXKigIxkizWN2ateuzdatWwkJCWHRokV8/fXXPPjgg+zdu5c6depkRI0iIuJskpOhe3eYMwdcXWH+fHNeHZEMkObLWM5Il7FERDKRYUCPHjBjBri4wLx55u3mImmUrpex4uPj7Sf5t7l0FBZEROSODAN6974ZdL74QkFHMlyqwk6+fPmIjo6mUKFC5M2bF5vNluIYwzCw2WwkJSWle5EiIuIEDAP69YOPPgKbDWbNguees7oqyQFSFXbWr19P/vz5AdiwYUOGFiQiIk7IMGDgQPjwQ3P700+hSxdra5IcI1Vhp169egBcv36djRs38n//938EBwdnaGEiIuIkDAOGDIEJE8ztjz+G55+3tibJUdJ0N5abmxvjxo277aSCIiIiKRgGvPEGjB1rbk+bBi+9ZG1NkuOk+dbzhg0bsnHjxoyoRUREnM0778DIkebzyZPhlVesrUdypDRPKti0aVOGDBnCvn37qFq1Kj4+Pg77mzdvnm7FiYhINvbee2bYAfjgA+jVy9p6JMdK8zw7Li537gzKrndjaZ4dEZF0NmoUvP66+XzcOHNwskg6y7DlIpKTk++rMBERcXLjxt0MOqNGKeiI5dIUdo4dO8batWtJTEykXr16lC9fPqPqEhGR7OiDD2DwYPP5e++Zd2GJWCzVYWfDhg089dRT/P333+YL3dz47LPP6NSpU4YVJyIi2cjkydC/v/n8rbfMu7BEsoBU3401bNgwHn/8cU6cOMG5c+d46aWXGHwjvYuISM42dSr06WM+/89/zLAjkkWkeoBy3rx5+fHHHylXrhwAV65cwdfXl5iYGAoUKJChRWY0DVAWEbkPH38ML79sPn/tNXOczm2WFRJJb6n9/k51z058fDwPPPCAfdvb2xsvLy/i4uLur1IREcm+PvvsZtAZMEBBR7KkNA1Q/vbbb/Hz87NvJycns27dOvbv329v0zw7IiI5xOefw4svms/79jXvwlLQkSwo1Zex7ja/jv1kmmdHRCRnmDsXOnc2l4Po2dMcnKygI5ks3efZ0fw6IiICwMKF5orlhmEu/6CgI1lcmtfGEhGRHGzJEujYEZKTzUtYH32koCNZnsKOiIikzrJl0KEDJCVBt24wYwakYoiDiNX0t1RERP7dihXQti1cv26O1Zk5U0FHsg39TRURkbtbtQratDGDznPPwaxZ4OpqdVUiqaawIyIid/btt9CqFSQmmj07c+Yo6Ei2c09hJzY2lpkzZzJ06FDOnz8PwC+//MKJEyfStTgREbHQ999DixZw7Rq0bg1ffgluaZqeTSRLSPPf2r179xIWFoafnx/Hjh3jpZdeIn/+/ERERPDXX3/x+eefZ0SdIiKSgZKSIDISoqMhMBDqJK7HtfnTkJAALVvC/PmQK5fVZYrckzT37PTv359u3bpx+PBhPD097e3NmjVj06ZN6VqciIhkvIgIKFYMGjQwh+S81WAjCU2ehqtX4emnzXl1FHQkG0tzz86OHTuYMWNGivbChQtz6tSpdClKREQyR0SEOfb4xlz6tdnMKp7E27jCKpqR2HExLd3drS1S5D6luWfHw8OD+Pj4FO2HDh2iYMGC6VKUiIhkvKQkc0mrG0HnUbaymqbk5jLf0pg2LKXPIA+y4SpAIg7SHHaaN2/Ou+++S2JiImCuh/XXX3/x2muv0bp163QvUEREMkZkJBw/bj6vzwbW8AR5uMT3NKIly7mKJ1FR5nEi2Vmaw8748eO5dOkShQoV4u+//6ZevXo8+OCD5MmThxEjRmREjSIikgGio80/OzCPb2mCH/GspwHNWcFVvFIcJ5JdpXnMjp+fH2vXrmXLli3s2bOHS5cuUaVKFcLCwjKiPhERySCBAQavMYbRDAVgIW3pyhwS8HQ8LtCK6kTSj80wblytvXexsbHkzZs3HcqxRmqXiBcRcRpJSST36o3L9GkAvM8ABjMW45YOf5sNgoPh6FHNIyhZU2q/v9N8GWvMmDEsXLjQvt22bVsKFChA4cKF2bNnz71VKyIimefKFWjVCpfp0zBsNvowicG291MEHYCJExV0JPtLc9iZPn06ISEhAKxdu5a1a9eyevVqmjZtyqBBg9K9QBERSUenT5sT6qxYAZ6e2JYupf7S3hQu7HhYcDAsWWKuFCGS3aV5zM6pU6fsYWflypW0bduWxo0bU6xYMWrUqJHuBYqISDo5fBieeAL++AMKFDADT61atMJcFcJhBuU66tER55HmsJMvXz6ioqIICQlhzZo1DB8+HADDMEjSZAwiIlnTtm3w1FNw7hwULw6rV0OpUvbdrq5Qv7515YlkpDSHnVatWvHcc89RsmRJzp07R9OmTQHYtWsXDz74YLoXKCIi92n5cujQwVz+4ZFHYOVKKFTI6qpEMk2aw84HH3xAsWLFiIqKYuzYseTOnRuA6OhoXn311XQvUERE7sOUKdCnjzlN8lNPwYIF4ONjdVUimSpdbj3P7nTruYg4neRkGDIExo0zt195BSZPBrc0/z+uSJaV2u/vNP+t//zzz++6v0uXLmk9pYiIpKeEBOjWzezFARg1Cl577eb95CI5TJp7dvLly+ewnZiYyJUrV3B3d8fb25vz58+na4GZQT07IuI0LlyAli1h0ybIlQs++ww6dbK6KpEMkWE9OxcuXEjRdvjwYXr06KF5dkRErPTnn9C0KRw4AL6+sGwZNGxodVUilkvzpIK3U7JkSUaPHk3fvn3T43QiIpJWu3bBo4+aQadwYdi8WUFH5H/SJewAuLm5cfLkyfQ6nYiIpNa330LdunDqFFSsaM6pU7Gi1VWJZBlpvoy1YsUKh23DMIiOjmbKlCnUrl073QoTEZFUmDULXnoJkpKgUSNYuhT8/KyuSiRLSXPYadmypcO2zWajYMGCNGzYkPHjx6dXXSIicjeGAe+8Yz7AHIT86afg7m5tXSJZUJrDTnJyckbUISIiqZWYCC+/bPbqALz+OgwfrlvLRe7gvmaXunHXuk3/gYmIZI6LF+HZZ81xOi4uMG0adO9udVUiWdo9DVD+/PPPqVixIl5eXnh5eVGpUiW++OKL9K5NRERuFR0N9eqZQcfbG776SkFHJBXS3LMzYcIEhg0bRq9evewDkjdv3swrr7zC2bNn6devX7oXKSKS4x04AE88AX/9ZS7iuXKluainiPyrNM+gHBoayjvvvJNiWYg5c+bw9ttvc/To0XQtMDNoBmURydI2bYIWLSA2FkqVgtWroXhxq6sSsVxqv7/TfBkrOjqaWrVqpWivVasW0dHRaT2diIjczcKF8PjjZtCpVQt+/FFBRySN0hx2HnzwQRYtWpSifeHChZQsWTJdihIRyfEMA95/H9q3h2vXoFUr+P57KFDA6spEsp00j9l55513aNeuHZs2bbKP2dmyZQvr1q27bQgSEZE0SkqCfv1g8mRzu29fGD8eXF2trUskm0pz2GndujXbt2/ngw8+YPny5QCULVuWn376icqVK6d3fSIiOcvff0PHjuYingATJpjBR0Tu2T3del61alW+/PJLdu7cyc6dO/nyyy8zJeiMHj0am81GeHi4ve3q1av07NmTAgUKkDt3blq3bk1MTEyG1yIiku7OnjUX71y2zJwJeeFCBR2RdJDqnp34+PhUHZdRdzPt2LGDGTNmUKlSJYf2fv36sWrVKhYvXoyfnx+9evWiVatWbNmyJUPqEBHJEL//Dk2bwuHDkC+fOYdOnTpWVyXiFFIddvLmzXvXmZINw8Bms5GUlJQuhd3q0qVLdOzYkU8++YThw4fb2+Pi4vj000+ZN28eDRs2BGDWrFmULVuWbdu28eijj6Z7LSIi6e6nn+Cpp+DMGSha1Ly1vGxZq6sScRqpDjsbNmywPzcMg2bNmjFz5kwKFy6cIYXdqmfPnjz55JOEhYU5hJ2dO3eSmJhIWFiYva1MmTIUKVKErVu3KuyISNb39dfQrp05VqdKFVi1CgICrK5KxKmkOuzUq1fPYdvV1ZVHH32U4hk838OCBQv45Zdf2LFjR4p9p06dwt3dnbx58zq0+/v7c+rUqTueMyEhgYSEBPt2ai/RiYikq2nToFcvSE42Z0devBhy57a6KhGnc08DlDNLVFQUffv2Ze7cuXh6eqbbeUeNGoWfn5/9ERISkm7nFhH5V8nJMHQovPqq+fyFF2DFCgUdkQySpcPOzp07OX36NFWqVMHNzQ03Nzc2btzIpEmTcHNzw9/fn2vXrhEbG+vwupiYGALu0g08dOhQ4uLi7I+oqKgM/iQiIv9z7Rp06QKjR5vb774Ln3wCuXJZW5eIE0vzPDu3utuA5fTQqFEj9u3b59D2/PPPU6ZMGV577TVCQkLIlSsX69ato3Xr1gAcPHiQv/76i5o1a97xvB4eHnh4eGRo7SIiKcTGmjMhb9gAbm5myOnWzeqqRJxeqsNOq1atHLavXr3KK6+8go+Pj0N7RERE+lQG5MmThwoVKji0+fj4UKBAAXv7Cy+8QP/+/cmfPz++vr707t2bmjVranCyiGQtUVHQrBns3w958sCSJdC4sdVVieQIqQ47fn5+DtudOnVK92LuxQcffICLiwutW7cmISGBJk2aMHXqVKvLEhG5ae9eM+icOAGBgfDNN/Dww1ZXJZJj2AzDMKwuwmqpXSJeRCTNvv/evHR18SKUK2fOoVOkiNVViTiF1H5/Z+kByiIi2drnn5uzIl+8CPXqwebNCjoiFlDYERFJb4YBI0ZA165w/Tq0bw/ffmsuAyEime6+7sYSEcnpkpIgMhKio83hOHVqXse196vmnVYAgwfDqFHgov+3FLGKwo6IyD2KiIC+feH4cXPbh0t85dmORle/McPNpEnQs6e1RYqIwo6IyL2IiIA2bcwrVgD+nGIlT1Ht6k6u4MWeQfOp2bOFtUWKCKAxOyIiaZaUZPbo3Ag6pTjIVmpSjZ2c4QEasZ5281qQlGRtnSJiUtgREUmjyMibl66asIYfqUUoxzhCCWqylW08SlSUeZyIWE9hR0QkjaKjwZXrjGQoa2hKAc6znerUZCu/86DDcSJiPY3ZERFJo2KuUfxABx5jCwAf8SoDGE8Cng7HBQZaUZ2I/JPCjohIWqxcyaM9umLjPHH48iIzWcKzDofYbBAcDHXqWFSjiDjQZSwRkdS4dg0GDoSnn8Z2/jwXSlSlKr+w1JYy6ABMnAiurplfpoikpLAjIvJvjh2DunVh/Hhzu08f8v13C2OXlqBwYcdDg4PNBc1btcr0KkXkDnQZS0TkbpYvh+efh9hYyJsXZs2Cli0BM9C0aPGPGZTrqEdHJKtR2BERuZ2EBHOph0mTzO0aNWDBAihWzOEwV1eoXz/TqxORNNBlLBGRf/r9d6hd+2bQGTAANm1KEXREJHtQz46IyK0WL4YXX4T4eMifH+bMgaeesroqEbkP6tkREQG4ehVefRXatjWDTu3asHu3go6IE1DYERE5dAgefRSmTTO3hw6FDRsgJMTaukQkXegylojkbPPmwcsvw6VL8MAD8OWX0KSJ1VWJSDpSz46I5ExXrsBLL0HHjmbQqVcP9uxR0BFxQgo7IpLzHDhg3ko+c6Y55fGwYfD99xAUZHVlIpIBdBlLRHKWOXPMgchXroC/v3nZKizM6qpEJAOpZ0dEcobLl6FbN/Nx5Qo0amTebaWgI+L0FHZExPnt3w/Vqpm9Oi4u8O678O23EBBgdWUikgl0GUtEnJdhwKefQu/e5jw6gYEwf745GFlEcgyFHRFxThcvwiuvmLeWg3mX1eefQ6FC1tYlIplOl7FExPns3m1etpo3z1ypc9Qo+OYbBR2RHEo9OyLiPAwDpk+Hfv3MVcuDg83LVo89ZnVlImIhhR0RcQ5xcdC9OyxaZG4/+aQ5ILlAAWvrEhHL6TKWiGR/P/8MVaqYQcfNDd5/H1asUNAREUA9OyKSnRkGTJ4MAwdCYiIULQoLFpiLeoqI/I/CjohkTxcuwAsvwLJl5nbLlvDZZ5Avn6VliUjWo8tYIpL9bN8OlSubQSdXLvjwQ4iIUNARkdtS2BGR7MMwYPx48+6qP/+E4sXhxx+hTx9zQU8RkdvQZSwRyR7OnTPXtVq50txu08ZctdzPz9KyRCTrU8+OiGR9W7aYl61WrgQPD5g61bzzSkFHRFJBYUdEsq7kZBg92lzLKioKSpaEbdugRw9dthKRVNNlLBHJms6cgS5dYM0ac7tDB5gxA/LksbYuEcl21LMjIlnPxo3w8MNm0PH0hE8+gblzFXRE5J6oZ0dELJGUBJGREB0NgYFQpw64kgQjR8Lbb5uXsMqUMcfmVKxodbkiko0p7IhIpouIgL594fjxm22VA0+x5oFOFNq3zmzo0gU++ghy57amSBFxGgo7IpKpIiLMu8YN42ZbQ9YxN7ojhaJjuO7hjdv0j8zbzEVE0oHG7IhIpklKMnt0bgQdF5J4m7dYy+MEEMN+ytMk3w6SOneztE4RcS4KOyKSaSIjb166Ksox1tGIt3gXFwxm8gLV+Yn1p8oRGWltnSLiXBR2RCTTREeDOwkMZSS/Uo76bOQSPnTkS15iJn/jbT9ORCS9aMyOiGSasifXsYeelOEgABuoz8vM4DClHI4LDLSiOhFxVgo7IpLxoqNhwAAenj8fgFP4M4DxzOM54OZMyDYbBAebt6GLiKQXXcYSkYxz/TpMnmzOlzN/Pri48HvTXpTlN+bbOvLPoAMwcSK4ulpSrYg4KYUdEckY27dD9erQpw/Ex8Mjj8BPP1Him8l8ujQvhQs7Hh4cDEuWQKtW1pQrIs5Ll7FEJH2dPw9Dh5pLPBgG5M1rLub54ov2LptWraBFi9vMoKweHRHJAAo7IpI+kpNhzhwYPBjOnjXbunWDMWOgUKEUh7u6Qv36mVqhiORQCjsicv/27oVXX4UtW8zt8uVh2jSNNBaRLEFjdkTk3l28CAMGQJUqZtDx8YFx42DXLgUdEcky1LMjImlnGOZo4vBwOHnSbGvdGj74AEJCLC1NROSfFHZEJG0OH4ZeveC778zt4sVhyhRo2tTaukRE7kCXsUQkdf7+G956CypUMIOOu7u5vX+/go6IZGnq2RGRf7d6NfTuDb//bm43bmz25pQsaW1dIiKpkKV7dkaNGsUjjzxCnjx5KFSoEC1btuTgwYMOx1y9epWePXtSoEABcufOTevWrYmJibGoYhEnExUFbdpAs2Zm0ClcGBYvhjVrFHREJNvI0mFn48aN9OzZk23btrF27VoSExNp3Lgxly9fth/Tr18/vv76axYvXszGjRs5efIkrTQFq8j9SUyE99+HsmVh6VJzUpwBA+DAATP82Gz/fg4RkSzCZhiGYXURqXXmzBkKFSrExo0bqVu3LnFxcRQsWJB58+bRpk0bAH777TfKli3L1q1befTRR1N13vj4ePz8/IiLi8PX1zcjP4JI1hcZCT16wH//a27XqmXOmVOpkrV1iYj8Q2q/v7N0z84/xcXFAZA/f34Adu7cSWJiImFhYfZjypQpQ5EiRdi6desdz5OQkEB8fLzDQyTHO33anPG4bl0z6BQoAJ99ZoYfBR0RycayTdhJTk4mPDyc2rVrU6FCBQBOnTqFu7s7efPmdTjW39+fU6dO3fFco0aNws/Pz/4I0bwgkpMlJcH06VC6tLncA0D37nDwIDz/PLhkm38mRERuK9v8K9azZ0/279/PggUL7vtcQ4cOJS4uzv6IiopKhwpFsqGdO83LVD16QGwsPPwwbN0KM2aYPTsiIk4gW9x63qtXL1auXMmmTZsIDg62twcEBHDt2jViY2MdendiYmIICAi44/k8PDzw8PDIyJJFsrbYWBg2DKZONRfw9PWF4cPN0OOWLf5ZEBFJtSzds2MYBr169WLZsmWsX7+e0NBQh/1Vq1YlV65crFu3zt528OBB/vrrL2rWrJnZ5YpkfYYBc+dCmTLmPDnJyfDcc/Dbb+Y8Ogo6IuKEsvS/bD179mTevHl89dVX5MmTxz4Ox8/PDy8vL/z8/HjhhRfo378/+fPnx9fXl969e1OzZs1U34klkmMcOGCuTP7DD+Z26dJmz07DhpaWJSKS0bL0ree2O8zlMWvWLLp16waYkwoOGDCA+fPnk5CQQJMmTZg6depdL2P9k249F6d2+bJ5ier99+H6dfDyMi9h9e8PupwrItlYar+/s3TYySwKO+KUDANWrIA+feCvv8y2p56CSZPgH5eERUSyo9R+f2fpy1gico+OHjVDzsqV5naRIjB5MjRvbm1dIiIWyNIDlEUkjRISYMQIKFfODDq5csHQofDrrwo6IpJjqWdHJJtJSjInNY6OhsBAqFPHXLqKdeugZ09zMkCABg3go4/M9a1ERHIwhR2RbCQiAvr2hePHb7ZVCYxmeYkBhGyebzb4+8OECdChgxbsFBFBYUck24iIMBccv3FLgSvXeZWpDI9+A9/oixguLth69oR334V/LKEiIpKTacyOSDaQlGT26NwIOjXYxg4eYRJ98eUi26nOkwV3kPTBJAUdEZF/UNgRyQYiI81LV1XYyWLasI2aVGY358nHy0ynJltZHVOFyEirKxURyXp0GUskqzMMrq/fxBpG0oTv7M2z6cpgxnKGQva26GgrChQRydoUdkSyKsMwbx8fNYqwrVsBuI4r8+nAGF7jv1RI8ZLAwMwuUkQk61PYEclqrl+HRYtg9GjYtw8Aw8ODL9z+j7cvD+IoKWc/ttkgONi8DV1ERBxpzI5IVnH1KsyYYS7Q2bGjGXRy54bBg7EdO0buz6dyzBaa4m7yG9sTJ/5vvh0REXGgsCNitYsXzUU6Q0PhlVfgjz/ggQfgvffMNa3GjIGAAFq1giVLoHBhx5cHB5vtrVpZU76ISFany1giVjl3zlyUc/JkuHDBbAsOhoED4cUXwccnxUtatYIWLe4wg7KIiNyWwo5IZjt+HMaPh48/hitXzLZSpWDIEPPylbv7XV/u6gr162d8mSIizkJhRySzHD5sXpL6/HNITDTbKleG11+HZ55R94yISAZR2BHJaLt3w6hR5sCa5GSzrV49czXyxo21fpWISAZT2BHJKJGRZshZvfpm21NPmSGnVi3r6hIRyWEUdkTSk2GY4WbUKNi82WxzcYF27cwxOZUqWVufiEgOpLAjkh6SkszLVKNGwZ49Zpu7O3TrBoMGwYMPWlqeiEhOprAjcj8SEuCLL8yBx0eOmG0+PuZ8Of37Q1CQtfWJiIjCjsg9uXTJvHV8/Hg4edJsy58f+vaFXr3M5yIikiUo7Iikxfnz5iSAkyaZz8Gc0njAAHjpJXN5BxERyVIUdkRS4+RJmDABpk+Hy5fNtgcfhNdeg86dwcPD2vpEROSOFHZE7ub332HsWJg9G65dM9seesi8fbxNG00EKCKSDSjsiNzO3r0wejQsXHhzIsDHHjNnO37iCU0EKCKSjSjsiNzqxx9h5EhYtepmW9OmZk9OnTrW1SUiIvdMYUdyhKSku6wUbhjw3XdmyNm0yWyz2eDZZ82JACtXtqxuERG5fwo74vQiIsw7wo8fv9kWHAwfTkiilW2ZGXJ27TJ35MoFXbvC4MFQsqQ1BYuISLpS2BGnFhFhjiM2jJttubhG4+NfUr7tGOCQ2ejtDS+/bE4EGBxsSa0iIpIxFHbEaSUlmT06N4KOL3F0YzYDeZ8QzG6eWJd8+L7eG5e+veGBByysVkREMorCjjityEiIPX6RDnxNWxbRlNV4YN4+fpJAxjOAj5O783WjPNRXzhERcVoKO+J8Ll+Gb76h+PsLOc0qvLhq3/UrZZlIOJ/ThQQ8AXPQsoiIOC+FHXEOV6/C6tXmvDhffw1XrlDkf7sOUZKFtGMRbdlPBcBxjpzAwEyvVkREMpHCjmRfCQnmLeMLF8KKFXDx4s19oaEkt2lLsznt+O70wxiknATQZjPHImv6HBER56awI9lLYiJ8/70ZcJYvh7i4m/tCQqBtW2jXDqpVw8Vmo/uj8F0bsy/n1juybkyAPHGiVnwQEXF2CjuS9V2/Dhs2mAFn2bKbq40DBAWZk/+1awc1aoCLi8NLW7WCJUtuP8/OxInmfhERcW4KO5I1JSWZsxkvXAhLl8LZszf3+fubk+e0awe1a6cIOP/UqhW0aHGXGZRFRMSpKexI1pGcDFu2wKJFZnfMqVM39z3wALRubQacunXTnFRcXaF+/fQtV0REsgeFHbGWYcD27WYPzuLFcOLEzX358pndMu3aQYMG4Ka/riIiknb69pDMZxiwc6cZcBYtgr/+urnP1xeeecYMOI0agbu7dXWKiIhTUNiRzGEYsGfPzYDzxx839+XObQ6qadsWmjQBDw/r6hQREaejsCMZa//+mwHn0KGb7d7e8PTTZsBp2hS8vKyrUUREnJrCjqS/334zw83ChfDrrzfbPT2hWTPzEtWTT4KPj3U1iohIjqGwI3eVlJTKW7aPHLkZcPbuvdnu7g5PPGEGnKefhjx5Mq12ERERUNiRu4iIuP1kfB9++L/J+I4eNe+gWrgQfvnl5kFubtC4sRlwWrQAP79Mr11EROQGhR25rYgIc96+W5dYALAdj2JL68XUL7mQ/Id/urnD1dW8e6pdO2jZEvLnz9R6RURE7kRhR1JISjJ7dAwDXEiiFId4nLW0YyG1+dE86DAYLi7Y6tc3A06rVubEfyIiIlmMwo7clJwMv//Owc9/Jvz4z1TjZ6rwC3m4dPMQbERSh0W0pePi1tRqFWBhwSIiIv9OYSenMgw4dgx+/vnmY+dOiIujHFDulkMv480OHmEZz7CENpykMACPJUAtK2oXERFJA4WdnMAwzFHGtwabn392XD38Bk9P4oo/zOe/VsPs26nGb5QhmZS3YAUGZkLtIiIi90lhxxlFR6cMNqdPpzwuVy546CGoVu3mo1w5crvkYmwxc5mqfw5QBrDZzLuy6tTJ8E8iIiJy3xR2srszZ1IGm5MnUx7n6goVKzoGmwoVbrs0gyvm7eVt2pjB5tbAY7OZf06cmOaFx0VERCyhsJOdnD9vjqu5NdjcuojmDS4uUK6cY7CpVClNSzK0agVLltx+np2JE/83z46IiEg2oLCTQVI98/CdxMenDDa3Lp55q9KlHYNN5crpshRDq1bmnID39TlEREQsprCTAf515uF/unQJdu92DDYHD97+5CVKOAabKlXA1zcjPgZgBpv69TPs9CIiIhlOYSed3Wnm4RMnzPaIuX/TMnSPY7A5cMCc4+afihZNGWw0M7GIiEiaKOyko1tnHgZwJ4GK7DNv4DbMG7krPLcfSEr54sKFHYNN1apQsGCm1i8iIuKMnCbsfPTRR4wbN45Tp07x0EMPMXnyZKpXr56pNURG3nrpyuAEhXmAcymOu5avEO61HnEMNpq0RkREJEM4RdhZuHAh/fv3Z/r06dSoUYOJEyfSpEkTDh48SKFChTKtjujoW7ds7KcCFdnHDh6xT9D3M9UYN6UwHZ6zZVpdIiIiOZnNMG43bVz2UqNGDR555BGmTJkCQHJyMiEhIfTu3ZshQ4b86+vj4+Px8/MjLi4O3/sY7PvDD9Cgwc1tX+KIxxdwDDYbNmjQr4iIyP1K7fe3SybWlCGuXbvGzp07CQsLs7e5uLgQFhbG1q1bb/uahIQE4uPjHR7poU4d866rGxPvxePHrUHHZoOQEM08LCIikpmyfdg5e/YsSUlJ+Pv7O7T7+/tz6tSp275m1KhR+Pn52R8hISHpUourq3l7OdwMPDdo5mERERFrZPuwcy+GDh1KXFyc/REVFZVu574x83Dhwo7twcFmu2YeFhERyVzZfoDyAw88gKurKzExMQ7tMTExBAQE3PY1Hh4eeNxmTaj0opmHRUREso5s37Pj7u5O1apVWbdunb0tOTmZdevWUbNmTcvqujHzcIcO5p8KOiIiItbI9j07AP3796dr165Uq1aN6tWrM3HiRC5fvszzzz9vdWkiIiJiMacIO+3atePMmTO8+eabnDp1iocffpg1a9akGLQsIiIiOY9TzLNzv9Jrnh0RERHJPDlmnh0RERGRu1HYEREREaemsCMiIiJOTWFHREREnJrCjoiIiDg1hR0RERFxak4xz879unH3fXqtfi4iIiIZ78b39r/NoqOwA1y8eBEg3VY/FxERkcxz8eJF/Pz87rhfkwpirqV18uRJ8uTJg81ms7qcLCc+Pp6QkBCioqI06WIWod9J1qLfR9ai30fWkpG/D8MwuHjxIkFBQbi43Hlkjnp2ABcXF4KDg60uI8vz9fXVPxxZjH4nWYt+H1mLfh9ZS0b9Pu7Wo3ODBiiLiIiIU1PYEREREaemsCP/ysPDg7feegsPDw+rS5H/0e8ka9HvI2vR7yNryQq/Dw1QFhEREaemnh0RERFxago7IiIi4tQUdkRERMSpKeyIiIiIU1PYkTsaNWoUjzzyCHny5KFQoUK0bNmSgwcPWl2W/M/o0aOx2WyEh4dbXUqOdeLECTp16kSBAgXw8vKiYsWK/Pzzz1aXlSMlJSUxbNgwQkND8fLyokSJErz33nv/umaSpJ9Nmzbx9NNPExQUhM1mY/ny5Q77DcPgzTffJDAwEC8vL8LCwjh8+HCm1KawI3e0ceNGevbsybZt21i7di2JiYk0btyYy5cvW11ajrdjxw5mzJhBpUqVrC4lx7pw4QK1a9cmV65crF69ml9//ZXx48eTL18+q0vLkcaMGcO0adOYMmUKBw4cYMyYMYwdO5bJkydbXVqOcfnyZR566CE++uij2+4fO3YskyZNYvr06Wzfvh0fHx+aNGnC1atXM7w23XouqXbmzBkKFSrExo0bqVu3rtXl5FiXLl2iSpUqTJ06leHDh/Pwww8zceJEq8vKcYYMGcKWLVuIjIy0uhQBnnrqKfz9/fn000/tba1bt8bLy4svv/zSwspyJpvNxrJly2jZsiVg9uoEBQUxYMAABg4cCEBcXBz+/v7Mnj2b9u3bZ2g96tmRVIuLiwMgf/78FleSs/Xs2ZMnn3ySsLAwq0vJ0VasWEG1atV49tlnKVSoEJUrV+aTTz6xuqwcq1atWqxbt45Dhw4BsGfPHjZv3kzTpk0trkwAjh49yqlTpxz+3fLz86NGjRps3bo1w99fC4FKqiQnJxMeHk7t2rWpUKGC1eXkWAsWLOCXX35hx44dVpeS4/3xxx9MmzaN/v378/rrr7Njxw769OmDu7s7Xbt2tbq8HGfIkCHEx8dTpkwZXF1dSUpKYsSIEXTs2NHq0gQ4deoUAP7+/g7t/v7+9n0ZSWFHUqVnz57s37+fzZs3W11KjhUVFUXfvn1Zu3Ytnp6eVpeT4yUnJ1OtWjVGjhwJQOXKldm/fz/Tp09X2LHAokWLmDt3LvPmzaN8+fLs3r2b8PBwgoKC9PsQXcaSf9erVy9WrlzJhg0bCA4OtrqcHGvnzp2cPn2aKlWq4ObmhpubGxs3bmTSpEm4ubmRlJRkdYk5SmBgIOXKlXNoK1u2LH/99ZdFFeVsgwYNYsiQIbRv356KFSvSuXNn+vXrx6hRo6wuTYCAgAAAYmJiHNpjYmLs+zKSwo7ckWEY9OrVi2XLlrF+/XpCQ0OtLilHa9SoEfv27WP37t32R7Vq1ejYsSO7d+/G1dXV6hJzlNq1a6eYiuHQoUMULVrUoopytitXruDi4viV5urqSnJyskUVya1CQ0MJCAhg3bp19rb4+Hi2b99OzZo1M/z9dRlL7qhnz57MmzePr776ijx58tivq/r5+eHl5WVxdTlPnjx5UoyX8vHxoUCBAhpHZYF+/fpRq1YtRo4cSdu2bfnpp5/4+OOP+fjjj60uLUd6+umnGTFiBEWKFKF8+fLs2rWLCRMm8H//939Wl5ZjXLp0iSNHjti3jx49yu7du8mfPz9FihQhPDyc4cOHU7JkSUJDQxk2bBhBQUH2O7YylCFyB8BtH7NmzbK6NPmfevXqGX379rW6jBzr66+/NipUqGB4eHgYZcqUMT7++GOrS8qx4uPjjb59+xpFihQxPD09jeLFixv/+c9/jISEBKtLyzE2bNhw2++Mrl27GoZhGMnJycawYcMMf39/w8PDw2jUqJFx8ODBTKlN8+yIiIiIU9OYHREREXFqCjsiIiLi1BR2RERExKkp7IiIiIhTU9gRERERp6awIyIiIk5NYUdEREScmsKOiIiIODWFHRGxO3PmDD169KBIkSJ4eHgQEBBAkyZN2LJli9Wl3bMffvgBm82W4vHGG2+k23sUK1aMiRMnptv5RCR9aW0sEbFr3bo1165dY86cORQvXpyYmBjWrVvHuXPnrC6Na9eu4e7ufs+vP3jwIL6+vvbt3Llzp0dZIpINqGdHRACIjY0lMjKSMWPG0KBBA4oWLUr16tUZOnQozZs3tx93+PBh6tati6enJ+XKlWPt2rXYbDaWL18O3OxJiY2Ntb9m9+7d2Gw2jh07BsC5c+fo0KEDhQsXxtvbm4oVKzJ//nyHeurXr0+vXr0IDw/ngQceoEmTJgDs37+fpk2bkjt3bvz9/encuTNnz579189XqFAhAgIC7I8bYefChQt06dKFfPny4e3tTdOmTTl8+LDDa5cuXUr58uXx8PCgWLFijB8/3qHOP//8k379+tl7jVL7GS9evEjHjh3x8fEhMDCQDz74gPr16xMeHm4/JiEhgYEDB1K4cGF8fHyoUaMGP/zww79+XhG5SWFHRACzpyN37twsX76chISE2x6TnJxMq1atcHd3Z/v27UyfPp3XXnstze919epVqlatyqpVq9i/fz/du3enc+fO/PTTTw7HzZkzB3d3d7Zs2cL06dOJjY2lYcOGVK5cmZ9//pk1a9YQExND27Zt7+kzA3Tr1o2ff/6ZFStWsHXrVgzDoFmzZiQmJgKwc+dO2rZtS/v27dm3bx9vv/02w4YNY/bs2QBEREQQHBzMu+++S3R0NNHR0an+jP3792fLli2sWLGCtWvXEhkZyS+//OJQX69evdi6dSsLFixg7969PPvsszzxxBMpApmI3EWmLDcqItnCkiVLjHz58hmenp5GrVq1jKFDhxp79uyx7//2228NNzc348SJE/a21atXG4CxbNkywzBurnx84cIF+zG7du0yAOPo0aN3fO8nn3zSGDBggH27Xr16RuXKlR2Oee+994zGjRs7tEVFRRnAHVdPvlGPj4+Pw+Ps2bPGoUOHDMDYsmWL/fizZ88aXl5exqJFiwzDMIznnnvOePzxxx3OOWjQIKNcuXL27aJFixoffPDBHT/b7T5jfHy8kStXLmPx4sX2/bGxsYa3t7d9Jfs///zTcHV1dfh5G4ZhNGrUyBg6dOi/vp+ImDRmR0TsWrduzZNPPklkZCTbtm1j9erVjB07lpkzZ9KtWzcOHDhASEgIQUFB9tfUrFkzze+TlJTEyJEjWbRoESdOnODatWskJCTg7e3tcFzVqlUdtvfs2cOGDRtuO97m999/p1SpUnd8z8jISPLkyWPfzpcvH1u2bMHNzY0aNWrY2wsUKEDp0qU5cOAAAAcOHKBFixYO56pduzYTJ04kKSkJV1fXe/qMf/zxB4mJiVSvXt3+Gj8/P0qXLm3f3rdvH0lJSSk+V0JCAgUKFLjjZxURRwo7IuLA09OTxx9/nMcff5xhw4bx4osv8tZbb9GtW7dUvd7Fxbw6bhiGve3GJaEbxo0bx4cffsjEiROpWLEiPj4+hIeHc+3aNYfjfHx8HLYvXbrE008/zZgxY1K8b2Bg4F3rCg0NJW/evKn6DOkhtZ/xbi5duoSrqys7d+5MEao0wFok9RR2ROSuypUrZx98XLZsWaKiooiOjraHi23btjkcX7BgQQCio6PJly8fYA5QvtWWLVto0aIFnTp1AsyxQIcOHaJcuXJ3raVKlSosXbqUYsWK4eZ2//98lS1bluvXr7N9+3Zq1aoFmAOLDx48aK+lbNmyKW6937JlC6VKlbIHEHd3d5KSktL0GYsXL06uXLnYsWMHRYoUASAuLo5Dhw5Rt25dACpXrkxSUhKnT5+mTp069/15RXIqDVAWEcD8km/YsCFffvkle/fu5ejRoyxevJixY8faL+OEhYVRqlQpunbtyp49e4iMjOQ///mPw3kefPBBQkJCePvttzl8+DCrVq1yuHsJoGTJkqxdu5Yff/yRAwcO8PLLLxMTE/OvNfbs2ZPz58/ToUMHduzYwe+//863337L888/nyJspEbJkiVp0aIFL730Eps3b2bPnj106tSJwoUL2z/zgAEDWLduHe+99x6HDh1izpw5TJkyhYEDB9rPU6xYMTZt2sSJEyfsd4b922fMkycPXbt2ZdCgQWzYsIH//ve/vPDCC7i4uNjv6CpVqhQdO3akS5cuREREcPToUX766SdGjRrFqlWr0vx5RXIsqwcNiUjWcPXqVWPIkCFGlSpVDD8/P8Pb29soXbq08cYbbxhXrlyxH3fw4EHjscceM9zd3Y1SpUoZa9ascRigbBiGsXnzZqNixYqGp6enUadOHWPx4sUOA5TPnTtntGjRwsidO7dRqFAh44033jC6dOlitGjRwn6OevXq2Qfq3urQoUPGM888Y+TNm9fw8vIyypQpY4SHhxvJycm3/Vy3GzB9q/PnzxudO3c2/Pz8DC8vL6NJkybGoUOHHI5ZsmSJUa5cOSNXrlxGkSJFjHHjxjns37p1q1GpUiXDw8PDuPHPamo+Y3x8vPHcc88Z3t7eRkBAgDFhwgSjevXqxpAhQ+zHXLt2zXjzzTeNYsWKGbly5TICAwONZ555xti7d+9tP4+IpGQzjFsurIuI3AObzcayZcto2bKl1aVka5cvX6Zw4cKMHz+eF154wepyRJyGxuyIiFhk165d/Pbbb1SvXp24uDjeffddgBR3f4nI/VHYERGx0Pvvv8/Bgwdxd3enatWqREZG8sADD1hdlohT0WUsERERcWq6G0tEREScmsKOiIiIODWFHREREXFqCjsiIiLi1BR2RERExKkp7IiIiIhTU9gRERERp6awIyIiIk5NYUdERESc2v8DxncaaMU4LlsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}